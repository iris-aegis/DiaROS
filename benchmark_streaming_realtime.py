#!/usr/bin/env python3
"""
script1.wavã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã—ã¦å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬
- ãƒ—ãƒ­ã‚°ãƒ©ãƒ é–‹å§‹ï½çµ‚äº†ã¾ã§ã®å…¨ä½“æ™‚é–“ã‚’è¨ˆæ¸¬
- 1ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®å¹³å‡å‡¦ç†æ™‚é–“ã‚’è¨ˆç®—
"""

import numpy as np
import soundfile as sf
import time
import webrtcvad
import sys
import datetime # datetimeãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

def benchmark_streaming_realtime(audio_file):
    """script1.wavã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã—ã¦æ™‚é–“ã‚’è¨ˆæ¸¬"""
    print("=" * 80)
    print("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    print("=" * 80)

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    print(f"\n[INFO] éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {audio_file}")
    audio_data, sr = sf.read(audio_file)
    print(f"  ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {sr}Hz")
    print(f"  éŸ³å£°é•·: {len(audio_data)}ã‚µãƒ³ãƒ—ãƒ« ({len(audio_data)/sr:.2f}ç§’)")

    # ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if audio_data.ndim > 1:
        audio_data = np.mean(audio_data, axis=1)

    # float32ã«å¤‰æ›
    audio_data = audio_data.astype(np.float32)

    # VADè¨­å®š
    sample_rate = 16000
    frame_duration = 10  # ms
    CHUNK = int(sample_rate * frame_duration / 1000)  # 160ã‚µãƒ³ãƒ—ãƒ«

    # webRTC VADåˆæœŸåŒ–ï¼ˆMode 3ï¼‰
    vad = webrtcvad.Vad()
    vad.set_mode(3)

    print(f"\n[INFO] VADè¨­å®š:")
    print(f"  - ãƒ•ãƒ¬ãƒ¼ãƒ é•·: {frame_duration}ms ({CHUNK}ã‚µãƒ³ãƒ—ãƒ«)")
    print(f"  - VADãƒ¢ãƒ¼ãƒ‰: 3 (VERY_AGGRESSIVE)")
    print(f"  - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {sample_rate}Hz")

    # çŠ¶æ…‹ç®¡ç†
    sound_count = 0
    silent_count = 0
    silent_start_time_seconds = None
    speech_detected_for_200ms = False
    sound = np.empty(0, dtype='float32')
    previous_is_speech = None  # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®çŠ¶æ…‹

    # ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã¨VADåˆ¤å®šçµæœã‚’è¨˜éŒ²
    total_frames = 0
    speech_frames = 0
    silence_frames = 0

    # å‡¦ç†æ™‚é–“è¨ˆæ¸¬ç”¨ãƒªã‚¹ãƒˆ
    frame_processing_times = []

    print(f"\n[INFO] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†é–‹å§‹...")
    print("-" * 80)

    # ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®é–‹å§‹æ™‚åˆ»
    program_start_time = time.time()

    # 10msãƒãƒ£ãƒ³ã‚¯å˜ä½ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
    total_chunks = (len(audio_data) + CHUNK - 1) // CHUNK

    for chunk_idx in range(total_chunks):
        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–‹å§‹æ™‚åˆ»ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ï¼‰
        frame_start_time = time.time()

        # ç›¸å¯¾æ™‚åˆ»ã‚’è¨ˆç®—ï¼ˆç§’ï¼‰
        current_time_sec = (chunk_idx * frame_duration) / 1000.0

        # 10msãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
        start_idx = chunk_idx * CHUNK
        end_idx = min(start_idx + CHUNK, len(audio_data))
        audiodata = audio_data[start_idx:end_idx]

        # ä¸è¶³åˆ†ã‚’ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        if len(audiodata) < CHUNK:
            audiodata = np.pad(audiodata, (0, CHUNK - len(audiodata)))

        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        sound = np.concatenate([sound, audiodata])

        # webRTC VADåˆ¤å®š
        audio_int16 = (audiodata * 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()

        try:
            is_speech = vad.is_speech(audio_bytes, sample_rate)
            total_frames += 1

            # çŠ¶æ…‹é·ç§»ã®æ¤œå‡ºï¼ˆéŸ³å£°â†’ç„¡éŸ³ã€ç„¡éŸ³â†’éŸ³å£°ï¼‰
            if previous_is_speech is not None and previous_is_speech != is_speech:
                if not is_speech:
                    # éŸ³å£°ã‹ã‚‰ç„¡éŸ³ã¸
                    print(f"[{current_time_sec:.3f}s] éŸ³å£°çµ‚äº† â†’ ç„¡éŸ³é–‹å§‹")
                    silent_start_time_seconds = current_time_sec
                else:
                    # ç„¡éŸ³ã‹ã‚‰éŸ³å£°ã¸
                    if silent_start_time_seconds is not None:
                        silent_duration = current_time_sec - silent_start_time_seconds
                        print(f"[{current_time_sec:.3f}s] ç„¡éŸ³çµ‚äº† â†’ éŸ³å£°é–‹å§‹ (ç„¡éŸ³ç¶™ç¶š: {silent_duration*1000:.0f}ms)")
                    else:
                        print(f"[{current_time_sec:.3f}s] éŸ³å£°é–‹å§‹")
                    silent_start_time_seconds = None

            if not is_speech:
                silence_frames += 1
                if silent_start_time_seconds is None and sound_count > 0:
                    silent_start_time_seconds = current_time_sec
                silent_count += 1
                sound_count = 0

                # 100msç„¡éŸ³æ¤œå‡ºï¼ˆ100msã«é”ã—ãŸæ™‚ã®ã¿å‡ºåŠ›ï¼‰
                if silent_count == int(100 / frame_duration) and speech_detected_for_200ms:
                    if silent_start_time_seconds is not None:
                        silent_duration = current_time_sec - silent_start_time_seconds
                        print(f"[{current_time_sec:.3f}s] âœ“ 100msç„¡éŸ³æ¤œå‡ºå®Œäº†ï¼ˆç¶™ç¶š: {silent_duration*1000:.0f}msï¼‰")
            else:
                speech_frames += 1
                if silent_start_time_seconds is not None:
                    silent_start_time_seconds = None
                    silent_count = 0

                sound_count += 1

                # 200mséŸ³å£°æ¤œå‡º
                if sound_count >= (200 / frame_duration):
                    if not speech_detected_for_200ms:
                        print(f"[{current_time_sec:.3f}s] 200msä»¥ä¸Šã®éŸ³å£°ã‚’æ¤œå‡º")
                    speech_detected_for_200ms = True

            previous_is_speech = is_speech

        except Exception as e:
            print(f"[ERROR] VADå‡¦ç†ã‚¨ãƒ©ãƒ¼ at {current_time_sec:.3f}s: {e}")
            continue

        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†çµ‚äº†æ™‚åˆ»
        frame_end_time = time.time()
        frame_processing_time_ms = (frame_end_time - frame_start_time) * 1000
        frame_processing_times.append(frame_processing_time_ms)

        # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ™‚é–“ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›
        print(f"[{current_time_sec:.3f}s] å‡¦ç†æ™‚é–“: {frame_processing_time_ms:.4f}ms")

        # é€²æ—è¡¨ç¤º
        if (chunk_idx + 1) % (total_chunks // 10) == 0:
            progress = ((chunk_idx + 1) / total_chunks) * 100
            sys.stdout.write(f"\r[INFO] å‡¦ç†ä¸­... {progress:.0f}%")
            sys.stdout.flush()

    # ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®çµ‚äº†æ™‚åˆ»
    program_end_time = time.time()

    print("\r" + " " * 40 + "\r", end="")  # é€²æ—è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
    print("-" * 80)

    # è¨ˆæ¸¬çµæœ
    # frame_processing_timesã¯å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‡¦ç†æ™‚é–“ã®ãƒªã‚¹ãƒˆ
    if len(frame_processing_times) > 0:
        total_processing_time = sum(frame_processing_times)  # ms
    else:
        total_processing_time = 0

    program_total_time = (program_end_time - program_start_time) * 1000  # ms

    print(f"\n[çµæœ] è¨ˆæ¸¬æƒ…å ±:")
    print(f"  ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
    print(f"  éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ : {speech_frames} ({speech_frames/total_frames*100:.1f}%)")
    print(f"  ç„¡éŸ³ãƒ•ãƒ¬ãƒ¼ãƒ : {silence_frames} ({silence_frames/total_frames*100:.1f}%)")

    print(f"\n[çµæœ] å‡¦ç†æ™‚é–“:")
    print(f"  âœ… å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ™‚é–“ã®åˆè¨ˆ: {total_processing_time:.2f}ms")
    print(f"  ğŸ“Š ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“æ™‚é–“: {program_total_time:.2f}ms")
    print(f"  â±ï¸ å®ŸéŸ³å£°æ™‚é–“: {len(audio_data)/sample_rate*1000:.2f}ms")

    # 1ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ãŸã‚Šã®å¹³å‡å‡¦ç†æ™‚é–“
    avg_time_per_frame = total_processing_time / total_frames if total_frames > 0 else 0

    print(f"\n[çµæœ] ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®å‡¦ç†æ™‚é–“çµ±è¨ˆ:")
    print(f"  1ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ10msï¼‰ã‚ãŸã‚Šã®å¹³å‡å‡¦ç†æ™‚é–“: {avg_time_per_frame:.4f}ms")
    print(f"  ç›¸å¯¾å‡¦ç†è² è·: {avg_time_per_frame/10*100:.2f}% (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ä»¶: < 1%)")

    # è©³ç´°ãªçµ±è¨ˆæƒ…å ±
    if len(frame_processing_times) > 0:
        min_frame_time = min(frame_processing_times)
        max_frame_time = max(frame_processing_times)
        median_frame_time = np.median(frame_processing_times)
        p95_frame_time = np.percentile(frame_processing_times, 95)
        p99_frame_time = np.percentile(frame_processing_times, 99)

        print(f"\n[è©³ç´°] ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†æ™‚é–“ã®åˆ†å¸ƒ:")
        print(f"  æœ€å°: {min_frame_time:.4f}ms")
        print(f"  æœ€å¤§: {max_frame_time:.4f}ms")
        print(f"  ä¸­å¤®å€¤: {median_frame_time:.4f}ms")
        print(f"  P95: {p95_frame_time:.4f}ms")
        print(f"  P99: {p99_frame_time:.4f}ms")

    # 1ç§’ã‚ãŸã‚Šã®æ¨å®šå‡¦ç†æ™‚é–“
    estimated_1sec = avg_time_per_frame * 100  # 100ãƒ•ãƒ¬ãƒ¼ãƒ  = 1ç§’

    print(f"\n[æ¨å®š] 1ç§’é–“ã®å‡¦ç†æ™‚é–“:")
    print(f"  æ¨å®šå‡¦ç†æ™‚é–“: {estimated_1sec:.2f}ms")
    print(f"  ç›¸å¯¾å‡¦ç†è² è·: {estimated_1sec/1000*100:.2f}% (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ä»¶: < 1%)")

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š
    print(f"\n[åˆ¤å®š]")
    if avg_time_per_frame < 0.1:
        print(f"  âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†å¯èƒ½ï¼ˆä½™è£•åº¦: {(10 - avg_time_per_frame):.3f}ms/ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")
    else:
        print(f"  âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã«èª²é¡Œã‚ã‚Šï¼ˆè¶…é: {(avg_time_per_frame - 10):.3f}ms/ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")

    # æ¯”è¼ƒ
    print(f"\n[æ¯”è¼ƒ] ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã¨ã®æ¯”è¼ƒ:")
    print(f"  webRTC VAD (Mode 3å˜ä½“): 0.0011ms/ãƒ•ãƒ¬ãƒ¼ãƒ ")
    print(f"  æœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå…¨å‡¦ç†å«ã‚€ï¼‰: {avg_time_per_frame:.4f}ms/ãƒ•ãƒ¬ãƒ¼ãƒ ")
    print(f"  ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {avg_time_per_frame - 0.0011:.4f}ms/ãƒ•ãƒ¬ãƒ¼ãƒ ")

    return {
        'audio_file': audio_file,
        'total_frames': total_frames,
        'speech_frames': speech_frames,
        'silence_frames': silence_frames,
        'total_processing_time_ms': total_processing_time,
        'program_total_time_ms': program_total_time,
        'avg_time_per_frame_ms': avg_time_per_frame,
        'estimated_1sec_ms': estimated_1sec,
        'audio_duration_sec': len(audio_data) / sample_rate,
        'realtime_capable': avg_time_per_frame < 0.1,
        'frame_processing_times': frame_processing_times
    }

def main():
    start_time = datetime.datetime.now() # é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
    audio_file = '/workspace/script1.wav'
    result = benchmark_streaming_realtime(audio_file)
    end_time = datetime.datetime.now() # çµ‚äº†æ™‚åˆ»ã‚’å–å¾—
    
    total_time = end_time - start_time # å·®åˆ†ã‚’è¨ˆç®—
    total_ms = total_time.total_seconds() * 1000
    total_frames = result['total_frames']

    print("\n" + "=" * 80)
    print("çµ‚äº†")
    print("=" * 80)
    print(f"ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“: {total_ms:.2f} milliseconds") # å·®åˆ†ã‚’ãƒŸãƒªç§’ã§å‡ºåŠ›

    if total_frames > 0:
        avg_time = total_ms / total_frames
        print(f"1ãƒ•ãƒ¬ãƒ¼ãƒ (10ms)ã‚ãŸã‚Šã®å¹³å‡å‡¦ç†æ™‚é–“ (å…¨ä½“): {avg_time:.4f} milliseconds")

if __name__ == "__main__":
    main()
