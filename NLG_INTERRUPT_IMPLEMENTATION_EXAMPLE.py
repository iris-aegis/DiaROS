#!/usr/bin/env python3
"""
NaturalLanguageGeneration (naturalLanguageGeneration.py) ã¸ã®
å…·ä½“çš„ãªå®Ÿè£…ä¾‹

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€First stageç”Ÿæˆã®ä¸­æ–­æ©Ÿèƒ½ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®
ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

ã€ä½¿ç”¨æ–¹æ³•ã€‘
1. ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
2. naturalLanguageGeneration.py ã«åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆ
3. ãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰ã§å‹•ä½œç¢ºèªï¼š
   - python3 test_gemma3_interrupt.py
   - python3 test_first_second_stage_comparison.py
"""

import requests
import json
import time
import threading
from typing import Optional


class InterruptibleNLGExample:
    """
    First stage ä¸­æ–­æ©Ÿèƒ½ä»˜ã NLG ã®å®Ÿè£…ä¾‹
    """

    def __init__(self):
        """åˆæœŸåŒ–ï¼šä¸­æ–­åˆ¶å¾¡ç”¨ã®å¤‰æ•°ã‚’è¿½åŠ """
        # ===== æ–°è¦è¿½åŠ ï¼šä¸­æ–­åˆ¶å¾¡ç”¨å¤‰æ•° =====
        self.first_stage_thread = None  # First stageã‚¹ãƒ¬ãƒƒãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        self.cancel_first_stage = False  # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°
        self.first_stage_response = ""  # First stageçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.first_stage_start_time = None  # é–‹å§‹æ™‚åˆ»ï¼ˆè¨ˆæ¸¬ç”¨ï¼‰
        # ====================================

        # ãã®ä»–ã®æ—¢å­˜å¤‰æ•°
        self.current_stage = "first"
        self.ollama_host = "http://localhost:11434"
        self.model_name = "gemma3:4b"

    def update(self, words, stage="first", turn_taking_decision_timestamp_ns=0):
        """
        ã€ä¿®æ­£ç‰ˆã€‘stage ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’åˆ‡ã‚Šæ›¿ãˆ

        Args:
            words: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆéŸ³å£°èªè­˜çµæœï¼‰
            stage: 'first' or 'second' ã‚’æŒ‡å®š
            turn_taking_decision_timestamp_ns: TurnTakingåˆ¤å®šæ™‚åˆ»
        """

        self.current_stage = stage

        # ===== æ–°è¦è¿½åŠ ï¼šstageåˆ¥ã®å‡¦ç†åˆ†å² =====
        if stage == "first":
            # First stage: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éå„ªå…ˆå®Ÿè¡Œ
            print(f"[First stage] éå„ªå…ˆå‡¦ç†ã¨ã—ã¦é–‹å§‹")

            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            self.cancel_first_stage = False

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            self.first_stage_thread = threading.Thread(
                target=self._run_first_stage_background,
                args=(words,),
                daemon=True
            )
            self.first_stage_thread.start()
            # ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹ç›´å¾Œã«æˆ»ã‚‹ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãªã—ï¼‰

        elif stage == "second":
            # Second stage: First stageã‚’ä¸­æ–­ã—ã¦å„ªå…ˆå®Ÿè¡Œ
            print(f"[Second stage] First stageã®ä¸­æ–­ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡")

            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
            self.cancel_first_stage = True

            # First stageã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            if self.first_stage_thread and self.first_stage_thread.is_alive():
                self.first_stage_thread.join(timeout=0.1)
                print(f"[Second stage] First stageä¸­æ–­å®Œäº†")

            # Second stageã‚’å®Ÿè¡Œï¼ˆåŒæœŸçš„ã«ï¼‰
            self._run_second_stage_blocking(words)

        # ====================================

    def _run_first_stage_background(self, words):
        """
        ã€æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰ã€‘First stageç”Ÿæˆï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œç‰ˆï¼‰
        """
        print(f"[First stage] æ¨è«–é–‹å§‹: '{words}'")
        self.first_stage_start_time = time.perf_counter()

        result = self.generate_first_stage_with_cancellation(words)
        print(f"[First stage] æ¨è«–å®Œäº†: '{result}'")

    def _run_second_stage_blocking(self, words):
        """
        ã€æ–°è¦ãƒ¡ã‚½ãƒƒãƒ‰ã€‘Second stageç”Ÿæˆï¼ˆåŒæœŸå®Ÿè¡Œç‰ˆï¼‰
        """
        print(f"[Second stage] æ¨è«–é–‹å§‹")

        # First stageã®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
        first_stage_result = self.first_stage_response or "ã†ã‚“"

        # Second stageãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦
        second_stage_prompt = f"""ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã®ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
å…ˆã»ã©ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦çŸ­ã„ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚ãã‚Œã«ç¶šãã€ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å¾©å…ƒã—ãŸç™ºè©±ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã«è‡ªç„¶ã«ç¶šãã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’åˆ¶ç´„äº‹é …ã«å¾“ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{first_stage_result}

åˆ¶ç´„äº‹é …:
- ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- 20æ–‡å­—ç¨‹åº¦ã®ä¸€è¨€ã«åã‚ã¦ãã ã•ã„ã€‚

å‡ºåŠ›:"""

        result = self.generate_second_stage(second_stage_prompt)
        print(f"[Second stage] æ¨è«–å®Œäº†: '{result}'")

        return result

    def generate_first_stage_with_cancellation(self, query: str) -> str:
        """
        ã€ä¿®æ­£ç‰ˆã€‘First stageç”Ÿæˆï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«å¯èƒ½ï¼‰

        é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š
        1. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ç›£è¦–
        2. ä¸­æ–­æ¤œå‡ºæ™‚ï¼šresponse.close()ã§æ¥ç¶šã‚’åˆ‡æ–­
        3. çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        4. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        """

        url = f"{self.ollama_host}/api/generate"

        payload = {
            "model": self.model_name,
            "prompt": query,
            "temperature": 0.7,
            "num_predict": 10,  # First stageã¯çŸ­ã„
            "stream": True,
            "raw": False,
        }

        response = None
        result = ""

        try:
            response = requests.post(url, json=payload, stream=True, timeout=None)

            if response.status_code != 200:
                print(f"âŒ APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return "ã†ã‚“"

            for line in response.iter_lines():
                # ===== é‡è¦ï¼šã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ãƒã‚§ãƒƒã‚¯ =====
                if self.cancel_first_stage:
                    print(
                        f"â¸ï¸  First stageä¸­æ–­: {len(result)}ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ, çµæœ='{result}'"
                    )

                    # æ¥ç¶šã‚’åˆ‡æ–­
                    if response:
                        response.close()

                    # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ï¼ˆSecond stageã§ä½¿ç”¨ï¼‰
                    self.first_stage_response = result if result else "ã†ã‚“"

                    return result if result else "ã†ã‚“"

                # ==========================================

                if line:
                    try:
                        data = json.loads(line)
                        token_text = data.get("response", "")

                        if token_text:
                            result += token_text

                        # ç”Ÿæˆå®Œäº†ãƒ•ãƒ©ã‚°
                        if data.get("done", False):
                            break

                    except json.JSONDecodeError:
                        continue

            # ç”Ÿæˆå®Œäº†æ™‚
            print(f"âœ… First stageå®Œå…¨ç”Ÿæˆ: '{result}'")
            self.first_stage_response = result
            return result

        except Exception as e:
            print(f"âŒ First stageç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "ã†ã‚“"

        finally:
            if response:
                response.close()

    def generate_second_stage(self, query: str) -> str:
        """
        ã€æœªä¿®æ­£ã€‘Second stageç”Ÿæˆ

        æ—¢å­˜ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ä½¿ç”¨
        """

        url = f"{self.ollama_host}/api/generate"

        payload = {
            "model": self.model_name,
            "prompt": query,
            "temperature": 0.7,
            "num_predict": 30,  # Second stageã¯é•·ã‚ã®å¿œç­”
            "stream": True,
            "raw": False,
        }

        response = None
        result = ""

        try:
            response = requests.post(url, json=payload, stream=True, timeout=None)

            if response.status_code != 200:
                print(f"âŒ APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return ""

            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line)
                        token_text = data.get("response", "")

                        if token_text:
                            result += token_text

                        if data.get("done", False):
                            break

                    except json.JSONDecodeError:
                        continue

            return result

        except Exception as e:
            print(f"âŒ Second stageç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""

        finally:
            if response:
                response.close()


# ============================================================================
# ä½¿ç”¨ä¾‹
# ============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ”„ NLG ä¸­æ–­æ©Ÿèƒ½ã®å®Ÿè£…ä¾‹")
    print("=" * 70)

    nlg = InterruptibleNLGExample()

    # ===== ã‚·ãƒŠãƒªã‚ªï¼šFirst stageç”Ÿæˆä¸­ã«Second stageã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ =====

    # Step 1: First stageé–‹å§‹
    print("\nã€Step 1ã€‘First stageé–‹å§‹")
    nlg.update("ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­", stage="first")

    # Step 2: 100msã§ä¸­æ–­ã—ã¦Second stageé–‹å§‹
    print("\nã€Step 2ã€‘100mså¾…æ©Ÿå¾Œã«Second stageé–‹å§‹ï¼ˆFirst stageä¸­æ–­ï¼‰")
    time.sleep(0.1)
    nlg.update("ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­", stage="second")

    # Step 3: å‡¦ç†å®Œäº†å¾…æ©Ÿ
    time.sleep(1)

    print("\n" + "=" * 70)
    print("âœ… å®Ÿè£…ä¾‹å®Œäº†")
    print("=" * 70)

    print("\nğŸ’¡ å®Ÿè£…ãƒã‚¤ãƒ³ãƒˆ:")
    print("  1. update() ãƒ¡ã‚½ãƒƒãƒ‰ã§ stage ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å‡¦ç†ã‚’åˆ‡ã‚Šæ›¿ãˆ")
    print("  2. First stage ã¯è‡ªå‹•çš„ã«ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ")
    print("  3. Second stage é–‹å§‹æ™‚ã« cancel_first_stage ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ")
    print("  4. First stage ç”Ÿæˆãƒ«ãƒ¼ãƒ—ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯")
    print("  5. çµæœã¯ self.first_stage_response ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥")
    print("  6. Second stage ã§ first_stage_response ã‚’å‚ç…§")
