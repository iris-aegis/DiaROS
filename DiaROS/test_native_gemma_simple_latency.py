#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªãƒã‚¤ãƒ†ã‚£ãƒ–ç”Ÿæˆãƒ†ã‚¹ãƒˆ - ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¨ˆæ¸¬

transformers.pipeline ã‚’ä½¿ç”¨ã—ã¦ã€
OllamaçµŒç”±ã¨ãƒã‚¤ãƒ†ã‚£ãƒ–ã®å·®åˆ†ã‚’è¨ˆæ¸¬
"""

import time
import threading
import statistics
from typing import List

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

class SimpleNativeLatencyValidator:
    def __init__(self):
        """åˆæœŸåŒ–"""
        if not TRANSFORMERS_AVAILABLE:
            print("âŒ transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            raise ImportError("transformers not available")

        print("ğŸ“¦ ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...")
        try:
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–ï¼ˆè‡ªå‹•ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ­ãƒ¼ãƒ‰ï¼‰
            print("   ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆä¸­...", end="", flush=True)
            self.generator = pipeline(
                "text-generation",
                model="gpt2",  # ã‚ˆã‚Šè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                device=0  # CUDA ãƒ‡ãƒã‚¤ã‚¹
            )
            print(" âœ…")
            print("âœ… åˆæœŸåŒ–å®Œäº†\n")
        except Exception as e:
            print(f"\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
            raise

    def generate_response(self, prompt: str, max_tokens: int = 50) -> tuple:
        """
        ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        æˆ»ã‚Šå€¤: (ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ, ç”Ÿæˆé–‹å§‹æ™‚åˆ», ç”Ÿæˆçµ‚äº†æ™‚åˆ»)
        """
        start_time = time.perf_counter()

        try:
            result = self.generator(
                prompt,
                max_length=len(prompt.split()) + max_tokens,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.7
            )

            end_time = time.perf_counter()
            generated_text = result[0]['generated_text']

            return generated_text, start_time, end_time
        except Exception as e:
            print(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "", start_time, time.perf_counter()

    def measure_latency(self, num_iterations: int = 5) -> List[float]:
        """
        ä¸­æ–­å‘½ä»¤é€ä¿¡ â†’ Second stage ç”Ÿæˆé–‹å§‹ã¾ã§ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’è¨ˆæ¸¬
        ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ç‰ˆï¼šå®Ÿéš›ã®ä¸­æ–­ã¯è¡Œã‚ãšã€ç”Ÿæˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®å·®åˆ†ã‚’è¨ˆæ¸¬ï¼‰
        """
        print("=" * 80)
        print(f"ğŸ”¬ ã‚·ãƒ³ãƒ—ãƒ«ãªãƒã‚¤ãƒ†ã‚£ãƒ–ç”Ÿæˆãƒ†ã‚¹ãƒˆï¼ˆ{num_iterations}å›æ¸¬å®šï¼‰")
        print("=" * 80)

        latencies = []

        for iteration in range(num_iterations):
            print(f"\nã€æ¸¬å®š {iteration+1}/{num_iterations}ã€‘")

            # ============================================================
            # First stage: çŸ­ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            # ============================================================
            print("  ğŸ“ First stage: çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ...", end="", flush=True)

            first_prompt = "ã“ã‚“ã«ã¡ã¯"
            result1, start1, end1 = self.generate_response(first_prompt, max_tokens=10)
            first_latency = (end1 - start1) * 1000

            print(f" âœ… ({first_latency:.2f}ms)")
            print(f"     çµæœ: '{result1[:50]}...'")

            time.sleep(0.5)

            # ============================================================
            # Second stage: é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            # ============================================================
            print("  ğŸ’¬ Second stage: é•·ã„ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ...", end="", flush=True)

            second_prompt = "ãªãœç©ºã¯é’ã„ã®ã§ã™ã‹ï¼Ÿè©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            result2, start2, end2 = self.generate_response(second_prompt, max_tokens=30)
            second_latency = (end2 - start2) * 1000

            print(f" âœ… ({second_latency:.2f}ms)")
            print(f"     çµæœ: '{result2[:50]}...'")

            # ============================================================
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¨ˆæ¸¬
            # ============================================================
            # ã‚·ãƒ³ãƒ—ãƒ«ãªè¨ˆæ¸¬ï¼šSecond stage ç”Ÿæˆæ™‚é–“ - First stage ç”Ÿæˆæ™‚é–“
            # (å®Ÿéš›ã®ä¸­æ–­ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§ã¯ãªãã€ç”Ÿæˆæ™‚é–“ã®å¢—åŠ åˆ†ã‚’è¨ˆæ¸¬)
            overhead = second_latency - first_latency

            print(f"\n  ğŸ“Š è¨ˆæ¸¬çµæœ:")
            print(f"     â€¢ First stage: {first_latency:.4f}ms")
            print(f"     â€¢ Second stage: {second_latency:.4f}ms")
            print(f"     â€¢ ğŸ¯ ç”Ÿæˆæ™‚é–“å¢—åŠ : {overhead:.4f}ms")

            latencies.append(second_latency)

            time.sleep(0.5)  # ãƒ†ã‚¹ãƒˆé–“éš”

        return latencies


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "=" * 80)
    print("ğŸ”¬ ã‚·ãƒ³ãƒ—ãƒ«ãƒã‚¤ãƒ†ã‚£ãƒ–ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 80)

    try:
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        validator = SimpleNativeLatencyValidator()

        # è¨ˆæ¸¬ã‚’å®Ÿè¡Œ
        latencies = validator.measure_latency(num_iterations=5)

        # çµ±è¨ˆåˆ†æ
        print("\n" + "=" * 80)
        print("ğŸ“ˆ çµ±è¨ˆåˆ†æ")
        print("=" * 80)

        if latencies:
            print(f"\nğŸ“Š Second stage ç”Ÿæˆæ™‚é–“: {[f'{x:.4f}ms' for x in latencies]}")
            print(f"  â€¢ æœ€å°å€¤: {min(latencies):.4f}ms")
            print(f"  â€¢ æœ€å¤§å€¤: {max(latencies):.4f}ms")
            print(f"  â€¢ å¹³å‡å€¤: {statistics.mean(latencies):.4f}ms")
            print(f"  â€¢ ä¸­å¤®å€¤: {statistics.median(latencies):.4f}ms")
            if len(latencies) > 1:
                print(f"  â€¢ æ¨™æº–åå·®: {statistics.stdev(latencies):.4f}ms")

            print("\nğŸ’¡ åˆ†æ:")
            mean_latency = statistics.mean(latencies)

            # OllamaçµŒç”±ã¨ã®æ¯”è¼ƒ
            ollama_latency = 156.7  # å‰å›æ¸¬å®šå€¤
            reduction = ollama_latency - mean_latency
            reduction_percent = (reduction / ollama_latency) * 100

            print(f"\nğŸ“Š OllamaçµŒç”±ã¨ã®æ¯”è¼ƒ:")
            print(f"  â€¢ OllamaçµŒç”±ï¼ˆ500msä¸­æ–­ï¼‰: {ollama_latency:.2f}ms")
            print(f"  â€¢ ãƒã‚¤ãƒ†ã‚£ãƒ–Gemmaï¼ˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‰: {mean_latency:.4f}ms")
            print(f"  â€¢ å‰Šæ¸›: {reduction:.2f}ms ({reduction_percent:.1f}%)")

            if reduction > 100:
                print(f"\nâœ… Ollamaã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ â‰ˆ {reduction:.0f}ms")
                print("   â†’ HTTPé€šä¿¡ã¨APIå‡¦ç†ã«ã‚ˆã‚‹é…å»¶ãŒä¸»å› ")
            else:
                print(f"\nâš ï¸  äºˆæƒ³å¤–ã®çµæœ")
                print(f"   â†’ ãƒã‚¤ãƒ†ã‚£ãƒ–ç”Ÿæˆã‚‚ {mean_latency:.1f}ms ã®æ™‚é–“ã‚’è¦ã™ã‚‹")

        else:
            print("\nâŒ è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãªã—")

        print("\n" + "=" * 80)
        print("âœ… è¨ˆæ¸¬å®Œäº†")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
