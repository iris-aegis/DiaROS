#!/usr/bin/env python3
"""
First stageå®Œäº†/ä¸­æ–­ â†’ Second stageé–‹å§‹ã¾ã§ã®é…å»¶æ™‚é–“æ¯”è¼ƒ

ä»¥ä¸‹ã®2ã¤ã®ã‚·ãƒŠãƒªã‚ªã§ã€çŠ¶æ…‹é·ç§»ã®é…å»¶ã‚’æ¸¬å®šï¼š
1. ã‚·ãƒŠãƒªã‚ªAï¼ˆä¸­æ–­ã‚ã‚Šï¼‰: First stageä¸­æ–­å®Œäº† â†’ Second stageé–‹å§‹
2. ã‚·ãƒŠãƒªã‚ªBï¼ˆå®Œå…¨ç”Ÿæˆï¼‰: First stageç”Ÿæˆå®Œäº† â†’ Second stageé–‹å§‹
"""

import time
import subprocess
import requests
import json
from typing import Generator, Tuple
import sys
import threading
import statistics

class SwitchingLatencyValidator:
    def __init__(self, model_name: str = "gemma3:4b", ollama_host: str = "http://localhost:11434"):
        """åˆæœŸåŒ–"""
        print(f"ğŸ“¦ Ollama ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ä¸­: {model_name}")

        self.model_name = model_name
        self.ollama_host = ollama_host
        self.current_response = None
        self.response_closed = False

        try:
            response = requests.get(f"{ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                print(f"âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒç¨¼åƒä¸­: {ollama_host}")
        except requests.exceptions.RequestException:
            print(f"âš ï¸  Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚èµ·å‹•ä¸­...")
            self._start_ollama()

        self._check_model_available()
        print("âœ… åˆæœŸåŒ–å®Œäº†\n")

    def _start_ollama(self):
        """Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
        print("â–¶ Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            time.sleep(5)
            print("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ Ollamaèµ·å‹•å¤±æ•—: {e}")
            sys.exit(1)

    def _check_model_available(self):
        """ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                if self.model_name in model_names:
                    print(f"âœ… ãƒ¢ãƒ‡ãƒ« {self.model_name} ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ç¢ºèªå¤±æ•—: {e}")
            sys.exit(1)

    def generate_streaming(
        self,
        prompt: str,
        max_tokens: int = 50,
        temperature: float = 0.7
    ) -> Tuple[Generator[str, None, None], float]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆï¼ˆä¸­æ–­å¯èƒ½ï¼‰"""
        url = f"{self.ollama_host}/api/generate"

        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "temperature": temperature,
            "num_predict": max_tokens,
            "stream": True,
            "raw": False
        }

        def token_generator():
            try:
                self.response_closed = False
                self.current_response = requests.post(url, json=payload, stream=True, timeout=None)

                if self.current_response.status_code != 200:
                    yield "APIã‚¨ãƒ©ãƒ¼"
                    return

                for line in self.current_response.iter_lines():
                    if self.response_closed:
                        self.current_response.close()
                        yield "[ä¸­æ–­]"
                        return

                    if line:
                        try:
                            data = json.loads(line)
                            token_text = data.get("response", "")
                            if token_text:
                                yield token_text
                            if data.get("done", False):
                                break
                        except json.JSONDecodeError:
                            continue

            except Exception as e:
                yield f"[ã‚¨ãƒ©ãƒ¼: {e}]"

        return token_generator(), time.time()

    def interrupt_generation(self):
        """ç”Ÿæˆã‚’ä¸­æ–­"""
        self.response_closed = True
        if self.current_response:
            try:
                self.current_response.close()
            except:
                pass

    def scenario_a_with_interrupt(self, num_iterations: int = 5) -> list:
        """
        ã‚·ãƒŠãƒªã‚ªA: First stageé€”ä¸­ã§ä¸­æ–­ â†’ Second stageé–‹å§‹ã¾ã§ã®é…å»¶ã‚’æ¸¬å®š
        """
        print("\n" + "="*70)
        print(f"ğŸ”´ ã‚·ãƒŠãƒªã‚ªA: First stageä¸­æ–­ â†’ Second stageé–‹å§‹ï¼ˆ{num_iterations}å›æ¸¬å®šï¼‰")
        print("="*70)

        first_stage_prompt = """ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã®ã¿ã‚’èª­ã¿å–ã‚Šã€
ã‚¿ãƒ¡å£ã§å¿œç­”ã™ã‚‹éš›ã®æœ€åˆã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

åˆ¶ç´„äº‹é …:
- å‡ºåŠ›ã¯ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ï¼ˆ2ï½5æ–‡å­—ç¨‹åº¦ï¼‰ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã ã‘ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
- ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã®ã‚¿ãƒ¡å£ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
  - è‚¯å®šãƒ»å…±æ„Ÿ: ã†ã‚“ã†ã‚“ã€ãã£ã‹ãƒ¼ã€ãªã‚‹ã»ã©
  - é©šããƒ»æ„Ÿå¿ƒ: ã¸ãƒ¼ã€ã™ã”ã„
  - ç¬‘é¡”ãƒ»æ¥½ã—ã„: ã‚ã¯ã¯ã€ã„ã„ã­
  - å›°æƒ‘ãƒ»åŒæƒ…: ãˆãƒ¼ã€ã¾ã˜ã‹

éŸ³å£°èªè­˜çµæœ: ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­
å‡ºåŠ›:"""

        second_stage_prompt_template = """ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã®ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
å…ˆã»ã©ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦çŸ­ã„ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚ãã‚Œã«ç¶šãã€ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã¾ãšä»¥ä¸‹ã®è¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰å…ƒã®ç™ºè©±ã‚’å¾©å…ƒã—ã¦ãã ã•ã„ã€‚
ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­

ãã®ä¸Šã§ã€å¾©å…ƒã—ãŸç™ºè©±ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã«è‡ªç„¶ã«ç¶šãã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’åˆ¶ç´„äº‹é …ã«å¾“ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{first_stage_result}

åˆ¶ç´„äº‹é …:
- ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚ã„ããªã‚Šã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
- 20æ–‡å­—ç¨‹åº¦ã®ä¸€è¨€ã«åã‚ã¦ãã ã•ã„ã€‚
- ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›:"""

        switching_latencies = []

        for iteration in range(num_iterations):
            print(f"\nã€æ¸¬å®š {iteration+1}/{num_iterations}ã€‘")

            # First stage: é€”ä¸­ã§ä¸­æ–­ï¼ˆ70mså¾Œï¼‰
            first_stage_result = ""
            first_stage_end_time = None

            def interrupt_after_delay():
                time.sleep(0.07)  # 70mså¾Œã«ä¸­æ–­
                self.interrupt_generation()

            interrupt_thread = threading.Thread(target=interrupt_after_delay, daemon=True)
            interrupt_thread.start()

            gen1, _ = self.generate_streaming(first_stage_prompt, max_tokens=10)
            for token in gen1:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    first_stage_result += token

            # First stageçµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆé«˜ç²¾åº¦è¨ˆæ¸¬ç”¨ï¼‰
            first_stage_end_time = time.perf_counter()

            # Second stageé–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆé«˜ç²¾åº¦è¨ˆæ¸¬ç”¨ï¼‰
            second_stage_start_time = time.perf_counter()
            switching_latency = (second_stage_start_time - first_stage_end_time) * 1000

            # Second stageã‚’å®Ÿè¡Œ
            second_stage_prompt = second_stage_prompt_template.format(first_stage_result=first_stage_result)
            second_stage_result = ""
            gen2, _ = self.generate_streaming(second_stage_prompt, max_tokens=30)
            for token in gen2:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    second_stage_result += token

            print(f"  â±ï¸  First stageçµ‚äº† â†’ Second stageé–‹å§‹: {switching_latency:.4f}ms")
            switching_latencies.append(switching_latency)

            time.sleep(0.5)

        return switching_latencies

    def scenario_b_without_interrupt(self, num_iterations: int = 5) -> list:
        """
        ã‚·ãƒŠãƒªã‚ªB: First stageå®Œå…¨ç”Ÿæˆ â†’ Second stageé–‹å§‹ã¾ã§ã®é…å»¶ã‚’æ¸¬å®š
        """
        print("\n" + "="*70)
        print(f"ğŸŸ¢ ã‚·ãƒŠãƒªã‚ªB: First stageå®Œå…¨ç”Ÿæˆ â†’ Second stageé–‹å§‹ï¼ˆ{num_iterations}å›æ¸¬å®šï¼‰")
        print("="*70)

        first_stage_prompt = """ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã®ã¿ã‚’èª­ã¿å–ã‚Šã€
ã‚¿ãƒ¡å£ã§å¿œç­”ã™ã‚‹éš›ã®æœ€åˆã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

åˆ¶ç´„äº‹é …:
- å‡ºåŠ›ã¯ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ï¼ˆ2ï½5æ–‡å­—ç¨‹åº¦ï¼‰ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã ã‘ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
- ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã®ã‚¿ãƒ¡å£ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
  - è‚¯å®šãƒ»å…±æ„Ÿ: ã†ã‚“ã†ã‚“ã€ãã£ã‹ãƒ¼ã€ãªã‚‹ã»ã©
  - é©šããƒ»æ„Ÿå¿ƒ: ã¸ãƒ¼ã€ã™ã”ã„
  - ç¬‘é¡”ãƒ»æ¥½ã—ã„: ã‚ã¯ã¯ã€ã„ã„ã­
  - å›°æƒ‘ãƒ»åŒæƒ…: ãˆãƒ¼ã€ã¾ã˜ã‹

éŸ³å£°èªè­˜çµæœ: ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­
å‡ºåŠ›:"""

        second_stage_prompt_template = """ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã®ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
å…ˆã»ã©ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦çŸ­ã„ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚ãã‚Œã«ç¶šãã€ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã¾ãšä»¥ä¸‹ã®è¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰å…ƒã®ç™ºè©±ã‚’å¾©å…ƒã—ã¦ãã ã•ã„ã€‚
ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­

ãã®ä¸Šã§ã€å¾©å…ƒã—ãŸç™ºè©±ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã«è‡ªç„¶ã«ç¶šãã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’åˆ¶ç´„äº‹é …ã«å¾“ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{first_stage_result}

åˆ¶ç´„äº‹é …:
- ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚ã„ããªã‚Šã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
- 20æ–‡å­—ç¨‹åº¦ã®ä¸€è¨€ã«åã‚ã¦ãã ã•ã„ã€‚
- ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›:"""

        switching_latencies = []

        for iteration in range(num_iterations):
            print(f"\nã€æ¸¬å®š {iteration+1}/{num_iterations}ã€‘")

            # First stage: å®Œå…¨ç”Ÿæˆ
            first_stage_result = ""
            first_stage_end_time = None

            gen1, _ = self.generate_streaming(first_stage_prompt, max_tokens=10)
            for token in gen1:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    first_stage_result += token

            # First stageçµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆé«˜ç²¾åº¦è¨ˆæ¸¬ç”¨ï¼‰
            first_stage_end_time = time.perf_counter()

            # Second stageé–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆé«˜ç²¾åº¦è¨ˆæ¸¬ç”¨ï¼‰
            second_stage_start_time = time.perf_counter()
            switching_latency = (second_stage_start_time - first_stage_end_time) * 1000

            # Second stageã‚’å®Ÿè¡Œ
            second_stage_prompt = second_stage_prompt_template.format(first_stage_result=first_stage_result)
            second_stage_result = ""
            gen2, _ = self.generate_streaming(second_stage_prompt, max_tokens=30)
            for token in gen2:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    second_stage_result += token

            print(f"  â±ï¸  First stageçµ‚äº† â†’ Second stageé–‹å§‹: {switching_latency:.4f}ms")
            switching_latencies.append(switching_latency)

            time.sleep(0.5)

        return switching_latencies


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*70)
    print("ğŸ” First stageå®Œäº†/ä¸­æ–­ â†’ Second stageé–‹å§‹ã¾ã§ã®é…å»¶æ¯”è¼ƒ")
    print("="*70)

    try:
        validator = SwitchingLatencyValidator()

        # ã‚·ãƒŠãƒªã‚ªA: ä¸­æ–­ã‚ã‚Š
        a_latencies = validator.scenario_a_with_interrupt(num_iterations=5)

        # ã‚·ãƒŠãƒªã‚ªB: å®Œå…¨ç”Ÿæˆ
        b_latencies = validator.scenario_b_without_interrupt(num_iterations=5)

        # çµ±è¨ˆåˆ†æ
        print("\n" + "="*70)
        print("ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ")
        print("="*70)

        print("\nğŸ”´ ã‚·ãƒŠãƒªã‚ªA: First stageä¸­æ–­å¾Œã®åˆ‡ã‚Šæ›¿ãˆé…å»¶")
        print(f"  â€¢ å€‹åˆ¥æ¸¬å®šå€¤: {[f'{x:.4f}ms' for x in a_latencies]}")
        print(f"  â€¢ æœ€å°å€¤: {min(a_latencies):.4f}ms")
        print(f"  â€¢ æœ€å¤§å€¤: {max(a_latencies):.4f}ms")
        print(f"  â€¢ å¹³å‡å€¤: {statistics.mean(a_latencies):.4f}ms")
        print(f"  â€¢ ä¸­å¤®å€¤: {statistics.median(a_latencies):.4f}ms")
        if len(a_latencies) > 1:
            print(f"  â€¢ æ¨™æº–åå·®: {statistics.stdev(a_latencies):.4f}ms")

        print("\nğŸŸ¢ ã‚·ãƒŠãƒªã‚ªB: First stageå®Œå…¨ç”Ÿæˆå¾Œã®åˆ‡ã‚Šæ›¿ãˆé…å»¶")
        print(f"  â€¢ å€‹åˆ¥æ¸¬å®šå€¤: {[f'{x:.4f}ms' for x in b_latencies]}")
        print(f"  â€¢ æœ€å°å€¤: {min(b_latencies):.4f}ms")
        print(f"  â€¢ æœ€å¤§å€¤: {max(b_latencies):.4f}ms")
        print(f"  â€¢ å¹³å‡å€¤: {statistics.mean(b_latencies):.4f}ms")
        print(f"  â€¢ ä¸­å¤®å€¤: {statistics.median(b_latencies):.4f}ms")
        if len(b_latencies) > 1:
            print(f"  â€¢ æ¨™æº–åå·®: {statistics.stdev(b_latencies):.4f}ms")

        # æ¯”è¼ƒåˆ†æ
        a_mean = statistics.mean(a_latencies)
        b_mean = statistics.mean(b_latencies)
        difference = a_mean - b_mean
        difference_ratio = (difference / b_mean) * 100 if b_mean != 0 else 0

        print("\n" + "="*70)
        print("ğŸ”¬ æ¯”è¼ƒåˆ†æ")
        print("="*70)
        print(f"\nä¸­æ–­æ™‚ã®åˆ‡ã‚Šæ›¿ãˆé…å»¶: {a_mean:.4f}ms")
        print(f"å®Œå…¨ç”Ÿæˆæ™‚ã®åˆ‡ã‚Šæ›¿ãˆé…å»¶: {b_mean:.4f}ms")
        print(f"å·®åˆ†: {difference:+.4f}ms ({difference_ratio:+.1f}%)")

        print("\nğŸ’¡ çµè«–:")
        if abs(difference) < 0.1:
            print("  âœ… ä¸¡ã‚·ãƒŠãƒªã‚ªã®åˆ‡ã‚Šæ›¿ãˆé…å»¶ã¯ã»ã¼åŒã˜")
            print("     ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®é…å»¶å·®ã¯ãªã„ï¼ˆè¨ˆæ¸¬èª¤å·®ç¯„å›²ï¼‰")
        elif difference > 0:
            print(f"  âš ï¸  ä¸­æ–­æ™‚ã®æ–¹ãŒç´„{difference:.3f}msé…ã„")
            print("     ä¸­æ–­å‡¦ç†ã«è‹¥å¹²ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒã‚ã‚‹å¯èƒ½æ€§")
        else:
            print(f"  â„¹ï¸  ä¸­æ–­æ™‚ã®æ–¹ãŒç´„{abs(difference):.3f}msé«˜é€Ÿ")
            print("     ä¸­æ–­æ™‚ã«è‹¥å¹²ã®ãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚‹å¯èƒ½æ€§")

        print("\n" + "="*70)
        print("âœ… æ¤œè¨¼å®Œäº†")
        print("="*70)

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
