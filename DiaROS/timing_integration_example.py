#!/usr/bin/env python3
"""
DiaROSæ™‚é–“è¨ˆæ¸¬çµ±åˆä¾‹
æ—¢å­˜ãƒãƒ¼ãƒ‰ã¸ã®çµ±åˆæ–¹æ³•ã®ã‚µãƒ³ãƒ—ãƒ«
"""

# 1. éŸ³å£°å…¥åŠ›ãƒãƒ¼ãƒ‰ï¼ˆspeech_inputï¼‰ã§ã®çµ±åˆä¾‹
class SpeechInputWithTiming:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker("main_pc")
        
    def detect_speech_start(self, audio_data):
        """éŸ³å£°é–‹å§‹æ¤œå‡ºæ™‚"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆï¼ˆéŸ³å£°é–‹å§‹æ™‚åˆ»ãƒ™ãƒ¼ã‚¹ï¼‰
        session_id = f"dialog_{int(time.time() * 1000)}"
        
        # è¨ˆæ¸¬é–‹å§‹
        self.time_tracker.start_session(session_id, "speech_input")
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¨ä¸€ç·’ã«session_idã‚’æ¬¡ã®ãƒãƒ¼ãƒ‰ã«é€ä¿¡
        return session_id, audio_data

# 2. éŸ³å£°èªè­˜ãƒãƒ¼ãƒ‰ï¼ˆASRï¼‰ã§ã®çµ±åˆä¾‹
class ASRWithTiming:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker("main_pc")
        
    def process_audio(self, session_id, audio_data):
        """éŸ³å£°èªè­˜å‡¦ç†"""
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¿½åŠ 
        self.time_tracker.add_checkpoint(session_id, "asr", "recognition_start")
        
        # æ—¢å­˜ã®éŸ³å£°èªè­˜å‡¦ç†
        result = self.recognize_speech(audio_data)
        
        # èªè­˜å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
        self.time_tracker.add_checkpoint(
            session_id, "asr", "recognition_complete", 
            {"text": result, "confidence": 0.95}
        )
        
        return session_id, result

# 3. å¯¾è©±ç®¡ç†ãƒãƒ¼ãƒ‰ï¼ˆDMï¼‰ã§ã®çµ±åˆä¾‹
class DialogManagementWithTiming:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker("main_pc")
        
    def process_dialogue(self, session_id, asr_result):
        """å¯¾è©±ç®¡ç†å‡¦ç†"""
        self.time_tracker.add_checkpoint(session_id, "dm", "dialogue_start")
        
        # æ—¢å­˜ã®å¯¾è©±ç®¡ç†å‡¦ç†
        response = self.generate_response(asr_result)
        
        self.time_tracker.add_checkpoint(
            session_id, "dm", "dialogue_complete", 
            {"response": response}
        )
        
        return session_id, response

# 4. è‡ªç„¶è¨€èªç”Ÿæˆãƒãƒ¼ãƒ‰ï¼ˆNLGï¼‰ã§ã®çµ±åˆä¾‹ï¼ˆåˆ¥PCï¼‰
class NLGWithTiming:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker("nlg_pc")  # åˆ¥PC
        
    def generate_response(self, session_id, dialogue_context):
        """å¿œç­”ç”Ÿæˆå‡¦ç†"""
        self.time_tracker.add_checkpoint(session_id, "nlg", "generation_start")
        
        # æ—¢å­˜ã®NLGå‡¦ç†
        response = self.call_llm_api(dialogue_context)
        
        self.time_tracker.add_checkpoint(
            session_id, "nlg", "generation_complete", 
            {"response": response, "model": "gpt-4"}
        )
        
        return session_id, response

# 5. éŸ³å£°åˆæˆãƒãƒ¼ãƒ‰ï¼ˆSSï¼‰ã§ã®çµ±åˆä¾‹
class SpeechSynthesisWithTiming:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker("main_pc")
        
    def synthesize_speech(self, session_id, text):
        """éŸ³å£°åˆæˆå‡¦ç†"""
        self.time_tracker.add_checkpoint(session_id, "ss", "synthesis_start")
        
        # æ—¢å­˜ã®éŸ³å£°åˆæˆå‡¦ç†
        audio_file = self.generate_audio(text)
        
        self.time_tracker.add_checkpoint(
            session_id, "ss", "synthesis_complete", 
            {"audio_file": audio_file}
        )
        
        return session_id, audio_file
    
    def play_audio(self, session_id, audio_file):
        """éŸ³å£°å†ç”Ÿé–‹å§‹"""
        self.time_tracker.add_checkpoint(session_id, "ss", "playback_start")
        
        # éŸ³å£°å†ç”Ÿå‡¦ç†
        self.play_sound(audio_file)
        
        # ğŸ¯ è¨ˆæ¸¬çµ‚äº†ï¼ˆç·è¨ˆæ™‚é–“è¨ˆç®—ï¼‰
        self.time_tracker.end_session(session_id, "ss")

# 6. çµ±åˆè¨ˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
class TimingReporter:
    def __init__(self):
        from diaros.timeTracker import get_time_tracker
        self.time_tracker = get_time_tracker()
    
    def generate_performance_report(self, session_id):
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timeline = self.time_tracker.get_session_timeline(session_id)
        
        if not timeline:
            return "ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        # å„æ®µéšã®å‡¦ç†æ™‚é–“è¨ˆç®—
        stages = {}
        for i in range(len(timeline) - 1):
            current = timeline[i]
            next_event = timeline[i + 1]
            
            stage_name = f"{current.node_name}â†’{next_event.node_name}"
            duration_ms = (next_event.timestamp_ns - current.timestamp_ns) / 1_000_000
            stages[stage_name] = duration_ms
        
        # ç·è¨ˆæ™‚é–“
        total_time_ms = (timeline[-1].timestamp_ns - timeline[0].timestamp_ns) / 1_000_000
        
        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        report = f"""
ğŸ“Š éŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ
ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}
ç·è¨ˆæ™‚é–“: {total_time_ms:.1f}ms

ğŸ” å„æ®µéšã®å‡¦ç†æ™‚é–“:
"""
        for stage, duration in stages.items():
            report += f"  {stage}: {duration:.1f}ms\n"
        
        # æ€§èƒ½è©•ä¾¡
        if total_time_ms < 1000:
            report += "\nâœ… å„ªç§€: 1ç§’ä»¥å†…ã§å¿œç­”å®Œäº†"
        elif total_time_ms < 2000:
            report += "\nğŸŸ¡ è‰¯å¥½: 2ç§’ä»¥å†…ã§å¿œç­”å®Œäº†"
        else:
            report += "\nğŸ”´ è¦æ”¹å–„: å¿œç­”æ™‚é–“ãŒé•·ã™ãã¾ã™"
        
        return report

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‹ã‚‰çµ‚äº†ã¾ã§
    session_id = "dialog_1234567890"
    
    # 1. éŸ³å£°å…¥åŠ›
    speech_input = SpeechInputWithTiming()
    session_id, audio = speech_input.detect_speech_start(b"audio_data")
    
    # 2. éŸ³å£°èªè­˜
    asr = ASRWithTiming()
    session_id, text = asr.process_audio(session_id, audio)
    
    # 3. å¯¾è©±ç®¡ç†
    dm = DialogManagementWithTiming()
    session_id, response = dm.process_dialogue(session_id, text)
    
    # 4. è‡ªç„¶è¨€èªç”Ÿæˆï¼ˆåˆ¥PCï¼‰
    nlg = NLGWithTiming()
    session_id, final_response = nlg.generate_response(session_id, response)
    
    # 5. éŸ³å£°åˆæˆãƒ»å†ç”Ÿ
    ss = SpeechSynthesisWithTiming()
    session_id, audio_file = ss.synthesize_speech(session_id, final_response)
    ss.play_audio(session_id, audio_file)
    
    # 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    reporter = TimingReporter()
    report = reporter.generate_performance_report(session_id)
    print(report)