#!/usr/bin/env python3
"""
ä¸­æ–­ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ¤œè¨¼ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

ä»¥ä¸‹ã®2ã¤ã®ã‚·ãƒŠãƒªã‚ªã‚’æ¯”è¼ƒã—ã¦ã€ä¸­æ–­å›ºæœ‰ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒã‚ã‚‹ã‹æ¤œè¨¼ã—ã¾ã™ï¼š
1. é€šå¸¸ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼šRequest 1å®Œäº† â†’ Request 2é–‹å§‹
2. ä¸­æ–­å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼šRequest 1ä¸­æ–­ â†’ Request 2é–‹å§‹

å„ã‚·ãƒŠãƒªã‚ªã§è¤‡æ•°å›å®Ÿè¡Œã—ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ™‚é–“ã‚’æ¸¬å®š
"""

import time
import subprocess
import requests
import json
from typing import Generator, List, Tuple
import sys
import threading
import statistics

class OverheadValidator:
    def __init__(self, model_name: str = "gemma3:4b", ollama_host: str = "http://localhost:11434"):
        """åˆæœŸåŒ–"""
        print(f"ğŸ“¦ Ollama ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ä¸­: {model_name}")

        self.model_name = model_name
        self.ollama_host = ollama_host
        self.current_response = None
        self.response_closed = False

        # ä¸­æ–­æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨ˆæ¸¬ç”¨
        self.interrupt_send_time = None

        # Ollamaã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç¢ºèª
        try:
            response = requests.get(f"{ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                print(f"âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒç¨¼åƒä¸­: {ollama_host}")
        except requests.exceptions.RequestException:
            print(f"âš ï¸  Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚èµ·å‹•ä¸­...")
            self._start_ollama()

        self._check_model_available()
        print("âœ… åˆæœŸåŒ–å®Œäº†\n")

    def _start_ollama(self):
        """Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
        print("â–¶ Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            time.sleep(5)
            print("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ Ollamaèµ·å‹•å¤±æ•—: {e}")
            sys.exit(1)

    def _check_model_available(self):
        """ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]
                if self.model_name in model_names:
                    print(f"âœ… ãƒ¢ãƒ‡ãƒ« {self.model_name} ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ç¢ºèªå¤±æ•—: {e}")
            sys.exit(1)

    def generate_streaming(
        self,
        prompt: str,
        max_tokens: int = 50,
        temperature: float = 0.7
    ) -> Tuple[Generator[str, None, None], float]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆï¼ˆä¸­æ–­å¯èƒ½ï¼‰"""
        url = f"{self.ollama_host}/api/generate"

        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "temperature": temperature,
            "num_predict": max_tokens,
            "stream": True,
            "raw": False
        }

        def token_generator():
            try:
                self.response_closed = False
                self.current_response = requests.post(url, json=payload, stream=True, timeout=None)

                if self.current_response.status_code != 200:
                    yield "APIã‚¨ãƒ©ãƒ¼"
                    return

                for line in self.current_response.iter_lines():
                    if self.response_closed:
                        self.current_response.close()
                        yield "[ä¸­æ–­]"
                        return

                    if line:
                        try:
                            data = json.loads(line)
                            token_text = data.get("response", "")
                            if token_text:
                                yield token_text
                            if data.get("done", False):
                                break
                        except json.JSONDecodeError:
                            continue

            except Exception as e:
                yield f"[ã‚¨ãƒ©ãƒ¼: {e}]"

        return token_generator(), time.time()

    def interrupt_generation(self):
        """ç”Ÿæˆã‚’ä¸­æ–­"""
        self.response_closed = True
        if self.current_response:
            try:
                self.current_response.close()
            except:
                pass

    def test_scenario_1_normal_consecutive_requests(self, num_iterations: int = 5) -> List[float]:
        """
        ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        Request 1å®Œäº† â†’ Request 2é–‹å§‹ã¾ã§ã®æ™‚é–“ã‚’æ¸¬å®š
        """
        print("\n" + "="*70)
        print(f"ğŸ“Š ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ{num_iterations}å›æ¸¬å®šï¼‰")
        print("="*70)

        prompt1 = "çŸ­ã„è³ªå•ã§ã™ã€‚5æ–‡å­—ä»¥å†…ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã“ã“ã¯ã©ã“ã§ã™ã‹?"
        prompt2 = "åˆ¥ã®çŸ­ã„è³ªå•ã§ã™ã€‚5æ–‡å­—ä»¥å†…ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã„ã¾ä½•æ™‚ã§ã™ã‹?"

        overhead_times = []

        for iteration in range(num_iterations):
            print(f"\nã€æ¸¬å®š {iteration+1}/{num_iterations}ã€‘")

            # Request 1ã‚’å®Œå…¨ã«å®Œäº†ã•ã›ã‚‹
            print("Request 1 å®Ÿè¡Œä¸­...", end="", flush=True)
            request1_start = time.time()
            result1 = ""
            gen1, _ = self.generate_streaming(prompt1, max_tokens=10)
            for token in gen1:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    result1 += token
            request1_end = time.time()
            print(f" å®Œäº† ({(request1_end - request1_start)*1000:.1f}ms)")

            # Request 2é–‹å§‹ã¾ã§ã®æ™‚é–“å·®ã‚’æ¸¬å®š
            request2_start = time.time()
            overhead = (request2_start - request1_end) * 1000  # ãƒŸãƒªç§’

            # Request 2ã‚’å®Ÿè¡Œï¼ˆãŸã ã—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ™‚é–“ã¯æ—¢ã«è¨˜éŒ²æ¸ˆã¿ï¼‰
            print("Request 2 å®Ÿè¡Œä¸­...", end="", flush=True)
            result2 = ""
            gen2, _ = self.generate_streaming(prompt2, max_tokens=10)
            for token in gen2:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    result2 += token
            request2_end = time.time()
            print(f" å®Œäº† ({(request2_end - request2_start)*1000:.1f}ms)")

            print(f"  â±ï¸  Request 1å®Œäº† â†’ Request 2é–‹å§‹: {overhead:.2f}ms")
            overhead_times.append(overhead)

            time.sleep(0.5)  # ãƒ†ã‚¹ãƒˆé–“éš”

        return overhead_times

    def test_scenario_2_interrupted_requests(self, num_iterations: int = 5) -> List[float]:
        """
        ã‚·ãƒŠãƒªã‚ª2: ä¸­æ–­å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        ä¸­æ–­å‘½ä»¤é€ä¿¡ â†’ Second stage APIå®Ÿè¡Œé–‹å§‹ã¾ã§ã®æ™‚é–“ã‚’æ¸¬å®š
        """
        print("\n" + "="*70)
        print(f"ğŸ“Š ã‚·ãƒŠãƒªã‚ª2: ä¸­æ–­å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆ{num_iterations}å›æ¸¬å®šï¼‰")
        print("="*70)

        prompt1 = "ã“ã‚Œã¯é•·ã„è³ªå•ã§ã€è©³ã—ã„èª¬æ˜ã‚’æ±‚ã‚ã¾ã™ã€‚ã§ãã‚‹ã ã‘é•·ãç­”ãˆã¦ãã ã•ã„ã€‚"
        prompt2 = "åˆ¥ã®çŸ­ã„è³ªå•ã§ã™ã€‚5æ–‡å­—ä»¥å†…ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã„ã¾ä½•æ™‚ã§ã™ã‹?"

        overhead_times = []

        for iteration in range(num_iterations):
            print(f"\nã€æ¸¬å®š {iteration+1}/{num_iterations}ã€‘")

            # Request 1ã‚’é€”ä¸­ã§ä¸­æ–­
            print("Request 1 å®Ÿè¡Œä¸­ï¼ˆ50mså¾Œã«ä¸­æ–­ï¼‰...", end="", flush=True)
            request1_start = time.time()
            result1 = ""

            # ä¸­æ–­å‘½ä»¤é€ä¿¡æ™‚åˆ»ã‚’ãƒªã‚»ãƒƒãƒˆ
            self.interrupt_send_time = None

            def interrupt_after_delay():
                time.sleep(0.05)  # 50msã§ä¸­æ–­ï¼ˆRequest 1å®Œäº†å‰ã«ä¸­æ–­ã•ã›ã‚‹ãŸã‚ï¼‰
                self.interrupt_send_time = time.perf_counter()  # ã€é‡è¦ã€‘ä¸­æ–­å‘½ä»¤é€ä¿¡æ™‚åˆ»ã‚’è¨˜éŒ²
                self.interrupt_generation()

            interrupt_thread = threading.Thread(target=interrupt_after_delay, daemon=True)
            interrupt_thread.start()

            gen1, _ = self.generate_streaming(prompt1, max_tokens=200)
            for token in gen1:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    result1 += token
            request1_end = time.time()
            print(f" ä¸­æ–­å®Œäº† ({(request1_end - request1_start)*1000:.1f}ms)")

            # Request 2ã‚’å®Ÿè¡Œ
            print("Request 2 å®Ÿè¡Œä¸­...", end="", flush=True)
            result2 = ""
            request2_start = time.time()  # Request 2å®Ÿè¡Œé–‹å§‹æ™‚åˆ»
            gen2_start_time = time.perf_counter()  # ã€é‡è¦ã€‘Second stage APIå®Ÿè¡Œé–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
            gen2, _ = self.generate_streaming(prompt2, max_tokens=10)
            for token in gen2:
                if token not in ["[ä¸­æ–­]", "[APIã‚¨ãƒ©ãƒ¼]"]:
                    result2 += token
            request2_end = time.time()
            print(f" å®Œäº† ({(request2_end - request2_start)*1000:.1f}ms)")

            # å®Ÿéš›ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ™‚é–“ã‚’è¨ˆç®—ï¼šä¸­æ–­å‘½ä»¤é€ä¿¡ â†’ Second stage APIå®Ÿè¡Œé–‹å§‹
            if self.interrupt_send_time is not None:
                overhead = (gen2_start_time - self.interrupt_send_time) * 1000  # ãƒŸãƒªç§’
            else:
                overhead = 0.0

            print(f"  â±ï¸  ä¸­æ–­å‘½ä»¤é€ä¿¡ â†’ Second stage APIå®Ÿè¡Œé–‹å§‹: {overhead:.4f}ms")
            overhead_times.append(overhead)

            time.sleep(0.5)  # ãƒ†ã‚¹ãƒˆé–“éš”

        return overhead_times


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*70)
    print("ğŸ” ä¸­æ–­ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æ¤œè¨¼")
    print("="*70)

    try:
        validator = OverheadValidator()

        # ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        normal_overheads = validator.test_scenario_1_normal_consecutive_requests(num_iterations=5)

        # ã‚·ãƒŠãƒªã‚ª2: ä¸­æ–­å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        interrupt_overheads = validator.test_scenario_2_interrupted_requests(num_iterations=5)

        # çµ±è¨ˆåˆ†æ
        print("\n" + "="*70)
        print("ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ")
        print("="*70)

        print("\nğŸ”µ ã‚·ãƒŠãƒªã‚ª1: é€šå¸¸ã®é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
        print(f"  â€¢ å€‹åˆ¥æ¸¬å®šå€¤: {[f'{x:.2f}ms' for x in normal_overheads]}")
        print(f"  â€¢ æœ€å°å€¤: {min(normal_overheads):.2f}ms")
        print(f"  â€¢ æœ€å¤§å€¤: {max(normal_overheads):.2f}ms")
        print(f"  â€¢ å¹³å‡å€¤: {statistics.mean(normal_overheads):.2f}ms")
        print(f"  â€¢ ä¸­å¤®å€¤: {statistics.median(normal_overheads):.2f}ms")
        if len(normal_overheads) > 1:
            print(f"  â€¢ æ¨™æº–åå·®: {statistics.stdev(normal_overheads):.2f}ms")

        print("\nğŸŸ  ã‚·ãƒŠãƒªã‚ª2: ä¸­æ–­å¾Œã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ")
        print(f"  â€¢ å€‹åˆ¥æ¸¬å®šå€¤: {[f'{x:.2f}ms' for x in interrupt_overheads]}")
        print(f"  â€¢ æœ€å°å€¤: {min(interrupt_overheads):.2f}ms")
        print(f"  â€¢ æœ€å¤§å€¤: {max(interrupt_overheads):.2f}ms")
        print(f"  â€¢ å¹³å‡å€¤: {statistics.mean(interrupt_overheads):.2f}ms")
        print(f"  â€¢ ä¸­å¤®å€¤: {statistics.median(interrupt_overheads):.2f}ms")
        if len(interrupt_overheads) > 1:
            print(f"  â€¢ æ¨™æº–åå·®: {statistics.stdev(interrupt_overheads):.2f}ms")

        # æ¯”è¼ƒ
        normal_mean = statistics.mean(normal_overheads)
        interrupt_mean = statistics.mean(interrupt_overheads)
        difference = interrupt_mean - normal_mean
        difference_ratio = (difference / normal_mean) * 100

        print("\n" + "="*70)
        print("ğŸ”¬ æ¯”è¼ƒåˆ†æ")
        print("="*70)
        print(f"\né€šå¸¸ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {normal_mean:.2f}ms")
        print(f"ä¸­æ–­å¾Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {interrupt_mean:.2f}ms")
        print(f"å·®åˆ†: {difference:+.2f}ms ({difference_ratio:+.1f}%)")

        print("\nğŸ’¡ çµè«–:")
        if abs(difference) < 5:
            print("  âœ… ä¸­æ–­å›ºæœ‰ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã¯ã»ã¼ãªã„")
            print("     ï¼ˆå·®åˆ† < 5ms = é€šå¸¸ã®ã‚†ã‚‰ãç¯„å›²å†…ï¼‰")
            print("     ä¸¡ã‚·ãƒŠãƒªã‚ªé–“ã«æœ‰æ„ãªå·®ãŒãªã„")
        elif difference > 0:
            print(f"  âš ï¸  ä¸­æ–­å¾Œã«ç´„{difference:.1f}msã®è¿½åŠ ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒç™ºç”Ÿ")
            print("     ä¸­æ–­å¾Œã®å†æ¥ç¶šå‡¦ç†ã«è‹¥å¹²ã®é…å»¶ã‚ã‚Š")
        else:
            print(f"  âœ… ä¸­æ–­å¾Œã®æ–¹ãŒç´„{abs(difference):.1f}msé«˜é€Ÿ")
            print("     ä¸­æ–­å›ºæœ‰ã®å•é¡Œãªã—")

        print("\n" + "="*70)
        print("âœ… æ¤œè¨¼å®Œäº†")
        print("="*70)

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
