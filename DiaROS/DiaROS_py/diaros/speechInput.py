### speechInput.py ###
import time
import pyaudio
from six.moves import queue
import sys
import rclpy
from std_msgs.msg import Float32MultiArray
import numpy as np

STREAMING_LIMIT = 10000

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±æœ‰ã‚­ãƒ¥ãƒ¼
stream_queue = queue.Queue()
# ROS Publisher ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å‚ç…§
ros_publisher = None

class SpeechInput:
    def __init__(self, rate, chunk_size, device):
        sys.stdout.write('speechInput start\n')
        self._rate = rate
        self.chunk_size = 160  # 10ms @ 16kHz
        self._num_channels = 1
        self._buff = queue.Queue()
        self.closed = True
        self.start_time = int(round(time.time() * 1000))
        self.restart_counter = 0
        self.audio_input = []
        self.last_audio_input = []
        self.result_end_time = 0
        self.is_final_end_time = 0
        self.final_request_end_time = 0
        self.bridging_offset = 0
        self.last_transcript_was_final = False
        self.new_stream = True
        self._audio_interface = pyaudio.PyAudio()
        self.mic_info = self._audio_interface.get_default_input_device_info()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paFloat32,
            channels=self._num_channels,
            rate=self._rate,
            input=True,
            input_device_index=self.mic_info["index"],
            frames_per_buffer=self.chunk_size,
            stream_callback=self._fill_buffer,
        )
        # acousticAnalysisã®ç‹¬ç«‹ã«ä¼´ã„ç„¡åŠ¹åŒ–
        # self.frequency = 0.0
        # self.grad = 0.0
        # self.power = 0.0
        # self.zerocross = 0
        # self.prevgrad = 0.0

    def __enter__(self):
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, *args, **kwargs):
        import time
        from datetime import datetime
        import numpy as np
        import hashlib
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æµ®å‹•å°æ•°ç‚¹é…åˆ—ã«å¤‰æ›
        audio_np = np.frombuffer(in_data, dtype=np.float32)
        
        # ä¸€æ„ã®éŸ³å£°IDã‚’ç”Ÿæˆï¼ˆå…ˆé ­10ã‚µãƒ³ãƒ—ãƒ« + ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒãƒƒã‚·ãƒ¥ï¼‰
        capture_timestamp = time.time()
        if len(audio_np) >= 10:
            sample_data = audio_np[:10].tobytes()
            timestamp_bytes = str(capture_timestamp).encode()
            audio_id = hashlib.md5(sample_data + timestamp_bytes).hexdigest()[:8]
        else:
            audio_id = hashlib.md5(str(capture_timestamp).encode()).hexdigest()[:8]
        
        # SDSéŸ³å£°å–å¾—ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæ¯å›ï¼‰
        timestamp_str = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        
        # ãƒ‡ãƒ¼ã‚¿å¯¾å¿œç¢ºèªç”¨: å…ˆé ­5ã‚µãƒ³ãƒ—ãƒ«ã®å…·ä½“çš„ãªå€¤ã‚’è¡¨ç¤º
        sample_values = audio_np[:5].tolist() if len(audio_np) >= 5 else audio_np.tolist()
        sample_str = '[' + ','.join([f'{v:.6f}' for v in sample_values]) + ']'
        
        sys.stdout.write(f"[ğŸ™ï¸ MIC_CAPTURE] {timestamp_str} | {capture_timestamp:.6f} | {sample_str}\n")
        sys.stdout.flush()
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«IDã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ä¸ã—ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        audio_data_with_metadata = {
            'audio_data': in_data,
            'audio_id': audio_id,
            'capture_timestamp': capture_timestamp,
            'sample_count': len(audio_np)
        }
        
        # ã‚­ãƒ¥ãƒ¼ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        stream_queue.put(audio_data_with_metadata)
        self._buff.put(in_data)
        
        # queueã«è¿½åŠ ã•ã‚ŒãŸã“ã¨ã‚’ROSå´ã«é€šçŸ¥
        if ros_publisher is not None:
            try:
                # é€šçŸ¥ç”¨ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—ï¼ˆéãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                ros_publisher._notify_new_data()
            except Exception as e:
                # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã§ã®ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°å‡ºåŠ›ã®ã¿
                pass
        
        return None, pyaudio.paContinue

    def generator(self):
        while not self.closed:
            data = []
            if self.new_stream and self.last_audio_input:
                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)
                if chunk_time != 0:
                    if self.bridging_offset < 0:
                        self.bridging_offset = 0
                    if self.bridging_offset > self.final_request_end_time:
                        self.bridging_offset = self.final_request_end_time
                    chunks_from_ms = round((self.final_request_end_time -
                                            self.bridging_offset) / chunk_time)
                    self.bridging_offset = (round((len(self.last_audio_input) - chunks_from_ms) * chunk_time))
                    for i in range(chunks_from_ms, len(self.last_audio_input)):
                        data.append(self.last_audio_input[i])
                self.new_stream = False

            chunk = self._buff.get()
            self.audio_input.append(chunk)

            if chunk is None:
                return
            data.append(chunk)

            while True:
                try:
                    chunk = self._buff.get(block=False)
                    if chunk is None:
                        return
                    data.append(chunk)
                    self.audio_input.append(chunk)
                except queue.Empty:
                    break

            yield b''.join(data)

def main():
    rate = 16000
    chunk_size = 160  # 10ms @ 16kHz
    device = 0
    speech_input = SpeechInput(rate, chunk_size, device)

    try:
        while True:
            time.sleep(1.0)
    except KeyboardInterrupt:
        pass
