# TurtTaking,back_channelã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’DiaROSå†…ã«å…¥ã‚Œã‚‹é–‹ç™º Unityã«jsonãƒ•ã‚¡ã‚¤ãƒ«ã§å…±æœ‰ã™ã‚‹ ä¸€æ—¦å±¥æ­´è«¦ã‚
from datetime import datetime, timedelta
import pygame
pygame.mixer.init()
import shutil
import os
import json
import requests
import wave
import sys
import numpy as np
import time
import subprocess
from diaros.timing_integration import get_timing_logger, log_audio_playback_start, end_timing_session

### VAD ###
import queue
import webrtcvad
import librosa
import pyaudio
import threading
###---###

### UDPé€šä¿¡è¨­å®š ###
import socket
HOST = '127.0.0.1'
PORT = 50021
client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
###---###

DEBUG = False

class SpeechSynthesis():
    # ### VAD ###
    # audio_queue = queue.Queue()  # ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ¥ãƒ¼
    # mic_sample_rate = 48000
    # sample_rate     = 16000
    # frame_duration  = 30  # ms
    # CHUNK           = int(mic_sample_rate * frame_duration / 1000)

    # vad = webrtcvad.Vad()
    # vad.set_mode(3)
    # sound_available = False
    # sound_count = 0
    # silent_count = 0
    # sound = np.empty(0) # ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹éŸ³å£°ã¾ã¨ã‚(é•·ã„)
    # ###---###
    
    # # audio start ###############################################################
    # def audiostart(self):
    #     audio = pyaudio.PyAudio() 

    #     # Sennheiser USB headset ã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’æ¢ã™ -----------------------------
    #     device_id = None
    #     for i in range(audio.get_device_count()):
    #         info = audio.get_device_info_by_index(i)
    #         # if 'Sennheiser USB headset' in info['name']:
    #         # if 'USB Microphone' in info['name']:
    #         if 'default' == info['name']:
    #             device_id = info['index']
    #             break
        
    #     # Sennheiser USB headset ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚‰çµ‚äº† ----------------------
    #     if device_id is None:
    #         print("Sennheiser USB headset ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    #         exit()

    #     # print(f"[Sennheiser USB headset] index:{device_id}")# ã‚¼ãƒ³ãƒã‚¤ã‚¶ãƒ¼ã‚’æŒ‡å®šã—ãŸæ™‚
    #     print(f"[Default] index:{device_id}")

    #     # è¦‹ã¤ã‹ã£ãŸãƒ‡ãƒã‚¤ã‚¹IDã‚’ä½¿ç”¨ã—ã¦ã€ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ã ---------------------
    #     stream = audio.open(format = pyaudio.paInt16,
    #                         rate = self.mic_sample_rate,
    #                         channels = 1, 
    #                         input = True, 
    #                         frames_per_buffer = self.CHUNK,
    #                         input_device_index=device_id)

    #     return audio, stream

    # # audio stop #############################################################
    # def audiostop(self, audio, stream):
    #     stream.stop_stream()
    #     stream.close()
    #     audio.terminate()

    # # ãƒã‚¤ã‚¯å…¥åŠ›ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ ##########################################
    # def mic_input_thread(self, sample_rate, CHUNK):
    #     (audio, stream) = self.audiostart()  # ã‚¹ãƒ¬ãƒƒãƒ‰å†…ã§audiostart()ã‚’å®Ÿè¡Œ

    #     while True:
    #         data = stream.read(CHUNK)
    #         audiodata = np.frombuffer(data, dtype='int16')
    #         self.audio_queue.put(audiodata)
        
    #     # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†æ™‚ã«audiostop()ã‚’å®Ÿè¡Œ
    #     self.audiostop(audio, stream)

    def __init__(self):
        self.tl = "ja"
        self.TMP_DIR = './tmp/'

        # remove TMP directory & remake ----
        if os.path.exists(self.TMP_DIR):
            du = shutil.rmtree(self.TMP_DIR)
            time.sleep(0.3)

        os.mkdir(self.TMP_DIR)

        self.speak_end = False
        self.response_pause_length = 1
        self.prev_response_time = datetime.now()
        self.source_words = []
        self.last_tts_file = ""  # ç›´è¿‘ã®åˆæˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¨˜éŒ²
        # power_calibration.wavã¯ç„¡åŠ¹åŒ–
        
        # æ™‚é–“è¨ˆæ¸¬ç”¨
        self.timing_logger = get_timing_logger()
        self.current_session_id = None

        # Check if VOICEVOX is running, start if not
        self._ensure_voicevox_running()
        # Check if VOICEVOX is running on GPU
        self._check_voicevox_gpu()

    def _ensure_voicevox_running(self):
        """Check if VOICEVOX is running and display status message"""
        try:
            import requests
            response = requests.get('http://localhost:50021/speakers', timeout=2)
            if response.status_code == 200:
                print("âœ“ VOICEVOX is running and ready")
                return
        except Exception:
            pass
        print("=" * 60)
        print("âš ï¸  VOICEVOX ENGINE IS NOT RUNNING")
        print("=" * 60)
        print("Please start VOICEVOX engine manually with one of these commands:")
        print("1. /opt/voicevox_engine/linux-nvidia/run --host 127.0.0.1 --port 50021")
        print("2. voicevox --host 127.0.0.1 --port 50021")
        print("=" * 60)
        print("Speech synthesis will fail until VOICEVOX is started.")
        print("=" * 60)

    def _check_voicevox_gpu(self):
        """VOICEVOXãŒGPUä¸Šã§å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã€è­¦å‘Šã‚’å‡ºã™"""
        try:
            import subprocess
            result = subprocess.run(['nvidia-smi', '--query-compute-apps=pid,process_name,gpu_uuid', '--format=csv,noheader'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            found = False
            for line in result.stdout.splitlines():
                if 'voicevox' in line.lower() or 'voicevox_engine' in line.lower():
                    found = True
                    break
            if found:
                print("âœ“ VOICEVOX ENGINE is running on GPU (nvidia-smi detected)")
            else:
                print("=" * 60)
                print("âš ï¸  VOICEVOX ENGINE IS NOT RUNNING ON GPU (nvidia-smi did not detect it)")
                print("=" * 60)
                print("Please ensure you are using the GPU version of VOICEVOX engine.")
                print("If you are using the CPU version, synthesis will be slow.")
                print("=" * 60)
        except Exception as e:
            print("Could not check GPU status (nvidia-smi not available or error).")
            # print(e)

    def play_sound(self, filename, block=True):
        """pygame.mixerã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿ"""
        try:
            # æ™‚é–“è¨ˆæ¸¬: éŸ³å£°å†ç”Ÿé–‹å§‹
            if self.current_session_id is None:
                sessions = self.timing_logger.session_data
                if sessions:
                    self.current_session_id = list(sessions.keys())[-1]  # æœ€æ–°ã‚»ãƒƒã‚·ãƒ§ãƒ³
            
            if self.current_session_id:
                log_audio_playback_start(self.current_session_id, filename)
            
            pygame.mixer.music.load(filename)
            pygame.mixer.music.play()
            
            if block:
                while pygame.mixer.music.get_busy():
                    pygame.time.wait(100)
                
                # æ™‚é–“è¨ˆæ¸¬: ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆéŸ³å£°å†ç”Ÿå®Œäº†ï¼‰
                if self.current_session_id:
                    total_ms = end_timing_session(self.current_session_id, "éŸ³å£°å†ç”Ÿå®Œäº†")
                    print(f"ğŸ‰ å¯¾è©±ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†: ç·è¨ˆæ™‚é–“ {total_ms:.1f}ms")
                    
        except Exception as e:
            print(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
    
    def trim_wav(self, input_file, output_file, trim_duration=0.1):# VOICEVOXã®ãƒã‚¤ã‚ºé™¤å»ç”¨
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
        with wave.open(input_file, 'rb') as input_wav:
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            params = input_wav.getparams()

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with wave.open(output_file, 'wb') as output_wav:
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
                output_wav.setparams(params)

                # 0.1 ç§’åˆ†ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¨ˆç®—
                trim_frames = int(trim_duration * params.framerate)

                # å…ˆé ­ã® 0.1 ç§’ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ®‹ã‚Šã‚’æ›¸ãè¾¼ã‚€
                input_wav.readframes(trim_frames)
                output_wav.writeframes(input_wav.readframes(params.nframes - trim_frames))

    def run(self, text):
        """NLGã‹ã‚‰å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å³åº§ã«éŸ³å£°åˆæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿”ã™ï¼ˆåŒæœŸå‡¦ç†ï¼‰"""
        tts_file = None
        try:
            speaker = 60
            start_time = datetime.now()
            host = "localhost"
            port = 50021
            params = (
                ('text', text),
                ('speaker', speaker),
            )
            response1 = requests.post(
                f'http://{host}:{port}/audio_query',
                params=params
            )
            response1_data = response1.json()
            response1_data["prePhonemeLength"] = 0.275
            response1_data["postPhonemeLength"] = 0.0
            modified_json_str = json.dumps(response1_data)
            all_segments = []
            for accent_phrase in response1_data['accent_phrases']:
                for mora in accent_phrase['moras']:
                    vowel_type = mora['vowel']
                    consonant_length = mora['consonant_length']
                    vowel_length = mora['vowel_length']
                    if consonant_length is None:
                        duration = vowel_length
                    else:
                        duration = vowel_length + consonant_length
                    segment = {
                        "vowel_type": vowel_type,
                        "length": duration
                    }
                    all_segments.append(segment)
                pause = 0.0
                if isinstance(accent_phrase['pause_mora'], dict):
                    pause_mora = accent_phrase['pause_mora']
                    pause_consonant_length = pause_mora['consonant_length']
                    pause_vowel_length = pause_mora['vowel_length']
                    if pause_consonant_length is not None:
                        pause += pause_consonant_length
                    if pause_vowel_length is not None:
                        pause += pause_vowel_length
                    pause_segment = {
                        "vowel_type": "silent_vowel",
                        "length": pause
                    }
                    all_segments.append(pause_segment)
            wrapped_data = {"data": all_segments}
            json_str = json.dumps(wrapped_data)
            current_time = datetime.now().strftime("%Y%m%d%H%M%S%f")
            json_file = './tmp/' + str(current_time) + '.json'
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(wrapped_data, f, ensure_ascii=False, indent=4)
            headers = {'Content-Type': 'application/json',}
            response2 = requests.post(
                f'http://{host}:{port}/synthesis',
                headers=headers,
                params=params,
                data=modified_json_str.encode('utf-8')
            )
            input_file = './{}/input_{}.wav'.format(self.TMP_DIR, current_time)
            with wave.open(input_file, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(24000)
                wf.writeframes(response2.content)
            tts_file = './tmp/' + str(current_time) + '.wav'
            self.trim_wav(input_file, tts_file)
            self.speak_end = True
            self.last_tts_file = tts_file  # æœ€æ–°ã®åˆæˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¸¸ã«ä¿æŒ
        except Exception as e:
            print('VOICEVOXerror: VOICEVOX sound is not generated. Do you launch VOICEVOX?')
            print(e.args)
            self.last_tts_file = ""
            self.speak_end = True
        return self.last_tts_file

    def updateNLG(self, nlg):
        """NLGã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°èªè­˜çµæœã‚’å—ä¿¡"""
        if nlg.get("reply"):
            self.txt = nlg["reply"]
            # â˜…æ™‚åˆ»æƒ…å ±ã‚’ä¿å­˜
            self.request_id = nlg.get("request_id", 0)
            self.worker_name = nlg.get("worker_name", "")
            self.start_timestamp_ns = nlg.get("start_timestamp_ns", 0)
            self.completion_timestamp_ns = nlg.get("completion_timestamp_ns", 0)
            self.inference_duration_ms = nlg.get("inference_duration_ms", 0.0)
            
            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼šæ™‚åˆ»æƒ…å ±å—ä¿¡ç¢ºèª
            now = datetime.now()
            timestamp = now.strftime('%H:%M:%S.%f')[:-3]
            print(f"[{timestamp}][DEBUG-speechSynthesis] æ™‚åˆ»æƒ…å ±å—ä¿¡:")
            print(f"[{timestamp}][DEBUG-speechSynthesis] start_ns: {self.start_timestamp_ns}")
            print(f"[{timestamp}][DEBUG-speechSynthesis] completion_ns: {self.completion_timestamp_ns}")
            print(f"[{timestamp}][DEBUG-speechSynthesis] request_id: {self.request_id}")
            print(f"[{timestamp}][DEBUG-speechSynthesis] worker_name: {self.worker_name}")
            sys.stdout.flush()
            
            # â˜…å—ä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–å‡ºåŠ›ã§ç¢ºèªï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼šå¿œç­”æ™‚ã®ã¿è¡¨ç¤ºï¼‰
            # from datetime import datetime
            # now = datetime.now()
            # timestamp = now.strftime('%H:%M:%S.%f')[:-3]
            # print(f"[{timestamp}][NLGå—ä¿¡ç¢ºèª] request_id:{self.request_id}, worker:{self.worker_name}")
            # print(f"[{timestamp}][NLGå—ä¿¡ç¢ºèª] start_ns:{self.start_timestamp_ns}, completion_ns:{self.completion_timestamp_ns}")
            # print(f"[{timestamp}][NLGå—ä¿¡ç¢ºèª] inference_ms:{self.inference_duration_ms}")
            # sys.stdout.flush()
            
            # â˜…éŸ³å£°èªè­˜çµæœãƒªã‚¹ãƒˆã‚’å—ä¿¡ãƒ»ä¿å­˜ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼šé »ç¹å‡ºåŠ›ã‚’é¿ã‘ã‚‹ï¼‰
            if nlg.get("source_words"):
                self.source_words = nlg["source_words"]
                # print(f"[SS] éŸ³å£°èªè­˜çµæœãƒªã‚¹ãƒˆå—ä¿¡: {len(self.source_words)}å€‹")
                # print(f"[SS] å¯¾è©±ç”Ÿæˆæ ¹æ‹ ã¨ãªã£ãŸéŸ³å£°èªè­˜å±¥æ­´ï¼ˆå…¨{len(self.source_words)}å€‹ï¼‰:")
                # for i, word in enumerate(self.source_words):
                #     print(f"    [{i+1:3d}] {word}")
                # sys.stdout.flush()
            else:
                self.source_words = []

if __name__ == "__main__":
    tts = SpeechSynthesis()

    while True:
        text = input('input: ')
        tts.run(text)