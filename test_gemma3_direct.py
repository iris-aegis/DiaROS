#!/usr/bin/env python3
"""
gemma3:4bãƒ¢ãƒ‡ãƒ«ã®ç›´æ¥å®Ÿè¡Œãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Ollamaã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ã€Pythonã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ç›´æ¥å®Ÿè¡Œã—ã¦ã€
ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ä¸­æ–­å¯èƒ½æ€§ã‚’æ¤œè¨¼ã—ã¾ã™
"""

import time
import subprocess
import requests
import json
from typing import Generator, Optional
import sys

class Gemma3DirectRunner:
    def __init__(self, model_name: str = "gemma3:4b", ollama_host: str = "http://localhost:11434"):
        """
        Gemma3ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–

        Args:
            model_name: Ollamaã®ãƒ¢ãƒ‡ãƒ«å
            ollama_host: Ollamaã®ãƒ›ã‚¹ãƒˆURL
        """
        print(f"ğŸ“¦ Ollama ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ä¸­: {model_name}")

        self.model_name = model_name
        self.ollama_host = ollama_host
        self.timeout_seconds = 60

        # Ollamaã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç¢ºèª
        try:
            response = requests.get(f"{ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                print(f"âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒç¨¼åƒä¸­: {ollama_host}")
            else:
                print(f"âš ï¸  Ollamaã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
                self._start_ollama()
        except requests.exceptions.RequestException:
            print(f"âš ï¸  Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚èµ·å‹•ä¸­...")
            self._start_ollama()

        # ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
        self._check_model_available()
        print("âœ… åˆæœŸåŒ–å®Œäº†\n")

    def _start_ollama(self):
        """Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
        print("â–¶ Ollamaã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            time.sleep(5)
            print("âœ… Ollamaã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ Ollamaèµ·å‹•å¤±æ•—: {e}")
            sys.exit(1)

    def _check_model_available(self):
        """ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]

                if self.model_name not in model_names:
                    print(f"âš ï¸  ãƒ¢ãƒ‡ãƒ« {self.model_name} ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    print(f"   åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {model_names}")
                    print(f"   ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­: ollama pull {self.model_name}")
                    try:
                        subprocess.run(
                            ["ollama", "pull", self.model_name],
                            check=True,
                            capture_output=True
                        )
                        print(f"âœ… ãƒ¢ãƒ‡ãƒ« {self.model_name} ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ")
                    except subprocess.CalledProcessError as e:
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—: {e}")
                        sys.exit(1)
                else:
                    print(f"âœ… ãƒ¢ãƒ‡ãƒ« {self.model_name} ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ç¢ºèªå¤±æ•—: {e}")
            sys.exit(1)

    def generate_streaming(
        self,
        prompt: str,
        max_tokens: int = 50,
        temperature: float = 0.7,
        timeout_seconds: Optional[float] = None
    ) -> Generator[str, None, None]:
        """
        ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆã‚’ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã§å®Ÿè¡Œ
        ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ©Ÿèƒ½ã¨ä¸­æ–­å¯èƒ½æ€§ã‚’ãƒ†ã‚¹ãƒˆ

        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            temperature: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦
            timeout_seconds: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰

        Yields:
            ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³
        """
        url = f"{self.ollama_host}/api/generate"

        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "temperature": temperature,
            "num_predict": max_tokens,
            "stream": True,
            "raw": False
        }

        start_time = time.time()
        first_token_time = None
        token_count = 0

        try:
            response = requests.post(url, json=payload, stream=True, timeout=timeout_seconds)

            if response.status_code != 200:
                print(f"\nâŒ APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                yield "[APIã‚¨ãƒ©ãƒ¼]"
                return

            for line in response.iter_lines():
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
                if timeout_seconds is not None:
                    elapsed = time.time() - start_time
                    if elapsed > timeout_seconds:
                        print(f"\nâ±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({elapsed:.2f}ç§’): ç”Ÿæˆã‚’ä¸­æ–­")
                        response.close()
                        yield "[ç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]"
                        return

                if line:
                    try:
                        data = json.loads(line)
                        token_text = data.get("response", "")

                        if token_text:
                            yield token_text
                            token_count += 1

                            # æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ™‚åˆ»ã‚’è¨˜éŒ²
                            if first_token_time is None:
                                first_token_time = time.time() - start_time

                        # ç”Ÿæˆå®Œäº†ãƒ•ãƒ©ã‚°
                        if data.get("done", False):
                            break
                    except json.JSONDecodeError:
                        continue

        except requests.exceptions.Timeout:
            print(f"\nâ±ï¸  ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            yield "[ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]"
            return
        except Exception as e:
            print(f"\nâŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            yield f"[ã‚¨ãƒ©ãƒ¼: {e}]"
            return

        # çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›
        total_time = time.time() - start_time
        if token_count > 0:
            print(f"\nğŸ“Š çµ±è¨ˆ:")
            print(f"  ãƒ»ç¬¬1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆæ™‚åˆ»: {first_token_time*1000:.1f}ms" if first_token_time else "  ãƒ»ç¬¬1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆæ™‚åˆ»: N/A")
            print(f"  ãƒ»åˆè¨ˆæ™‚é–“: {total_time*1000:.1f}ms")
            print(f"  ãƒ»ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: {token_count}")
            print(f"  ãƒ»å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ™‚é–“: {(total_time/token_count)*1000:.1f}ms")

    def test_first_stage(self):
        """
        First stage (ç›¸æ§Œç”Ÿæˆ) ã®ãƒ†ã‚¹ãƒˆ
        """
        print("\n" + "="*60)
        print("ğŸ¤ First Stage ãƒ†ã‚¹ãƒˆ (ç›¸æ§Œç”Ÿæˆ)")
        print("="*60)

        # First stageãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        asr_results = ["ã“ã‚“ã«ã¡ã¯", "ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­"]
        prompt = f"""ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã®ã¿ã‚’èª­ã¿å–ã‚Šã€
ã‚¿ãƒ¡å£ã§å¿œç­”ã™ã‚‹éš›ã®æœ€åˆã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å„éŸ³å£°èªè­˜çµæœã¯éŸ³å£°é•·5ç§’ã§ã€2.5ç§’ãšã¤ãšã‚‰ã—ã¦å–å¾—ã•ã‚Œã¦ã„ã¾ã™ã€‚
æœ€å¾Œã®éŸ³å£°èªè­˜çµæœã¯æœ€æ–°ã®éŸ³å£°ã‹ã‚‰2æ–‡å­—åˆ†é…ã‚Œã¦ã„ã¾ã™ã€‚

åˆ¶ç´„äº‹é …:
- å‡ºåŠ›ã¯ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ï¼ˆ2ï½5æ–‡å­—ç¨‹åº¦ï¼‰ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚å¥èª­ç‚¹ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ã‚¶ã®ã€Œæ„Ÿæƒ…ã€ã¨ã€Œç™ºè©±ã®æ„å›³ã€ã ã‘ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
- ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã¾ãŸã¯ãã‚Œã«æº–ãšã‚‹ã‚¿ãƒ¡å£ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
  - è‚¯å®šãƒ»å…±æ„Ÿ: ã†ã‚“ã†ã‚“ã€ãã£ã‹ãƒ¼ã€ãªã‚‹ã»ã©
  - é©šããƒ»æ„Ÿå¿ƒ: ã¸ãƒ¼ã€ã™ã”ã„
  - ç¬‘é¡”ãƒ»æ¥½ã—ã„: ã‚ã¯ã¯ã€ã„ã„ã­
  - å›°æƒ‘ãƒ»åŒæƒ…: ãˆãƒ¼ã€ã¾ã˜ã‹

éŸ³å£°èªè­˜çµæœ:
{', '.join(asr_results)}

å‡ºåŠ›:"""

        print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{prompt[:200]}...\n")
        print("â³ ç”Ÿæˆé–‹å§‹...")
        print("-" * 60)

        start_time = time.time()
        result = ""

        for token in self.generate_streaming(prompt, max_tokens=10, timeout_seconds=15.0):
            if token not in ["[ç”Ÿæˆå®Œäº†]", "[ç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]", "[APIã‚¨ãƒ©ãƒ¼]", "[ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]"]:
                print(token, end="", flush=True)
                result += token

        elapsed = time.time() - start_time
        print(f"\n-" * 60)
        print(f"âœ… First Stage ç”Ÿæˆå®Œäº†")
        print(f"â±ï¸  åˆè¨ˆæ™‚é–“: {elapsed*1000:.1f}ms")
        print(f"ğŸ“ çµæœ: {result.strip()}\n")

        return result.strip()

    def test_second_stage(self, first_stage_result: str):
        """
        Second stage (æœ¬å¿œç­”ç”Ÿæˆ) ã®ãƒ†ã‚¹ãƒˆ
        """
        print("\n" + "="*60)
        print("ğŸ’¬ Second Stage ãƒ†ã‚¹ãƒˆ (æœ¬å¿œç­”ç”Ÿæˆ)")
        print("="*60)

        # Second stageãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        asr_results = ["ã“ã‚“ã«ã¡ã¯", "ä»Šæ—¥ã¯å¤©æ°—ãŒã„ã„ã§ã™ã­"]
        asr_text = ", ".join(asr_results)

        prompt = f"""ã‚ãªãŸã¯ç”·æ€§ãƒ¦ãƒ¼ã‚¶ã®å‹é”ã§ã‚ã‚‹å„ªã—ãæ˜ã‚‹ã„æ€§æ ¼ã§ã‚ã‚‹å¥³æ€§ã®ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã§ã™ã€‚
å…ˆã»ã©ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦çŸ­ã„ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚ãã‚Œã«ç¶šãã€ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã¾ãšä»¥ä¸‹ã®è¤‡æ•°ã®ã¶ã¤åˆ‡ã‚Šã®éŸ³å£°èªè­˜çµæœã‹ã‚‰å…ƒã®ç™ºè©±ã‚’å¾©å…ƒã—ã¦ãã ã•ã„ã€‚
{asr_text}

ãã®ä¸Šã§ã€å¾©å…ƒã—ãŸç™ºè©±ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ã«è‡ªç„¶ã«ç¶šãã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’åˆ¶ç´„äº‹é …ã«å¾“ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{first_stage_result}

åˆ¶ç´„äº‹é …:
- ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¯ãƒ¼ãƒ‰ã€ï¼ˆã†ã‚“ã€ã¸ãƒ¼ã€ã‚ã¯ã¯ ç­‰ï¼‰ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚ã„ããªã‚Šã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
- 20æ–‡å­—ç¨‹åº¦ã®ä¸€è¨€ã«åã‚ã¦ãã ã•ã„ã€‚
- ã€Œã‚¿ãƒ¡å£ã®å¿œç­”ã€ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›:"""

        print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{prompt[:200]}...\n")
        print("â³ ç”Ÿæˆé–‹å§‹...")
        print("-" * 60)

        start_time = time.time()
        result = ""

        for token in self.generate_streaming(prompt, max_tokens=30, timeout_seconds=15.0):
            if token not in ["[ç”Ÿæˆå®Œäº†]", "[ç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]", "[APIã‚¨ãƒ©ãƒ¼]", "[ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]"]:
                print(token, end="", flush=True)
                result += token

        elapsed = time.time() - start_time
        print(f"\n-" * 60)
        print(f"âœ… Second Stage ç”Ÿæˆå®Œäº†")
        print(f"â±ï¸  åˆè¨ˆæ™‚é–“: {elapsed*1000:.1f}ms")
        print(f"ğŸ“ çµæœ: {result.strip()}\n")

        return result.strip()

    def test_timeout_interruption(self):
        """
        ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»ä¸­æ–­å¯èƒ½æ€§ã®ãƒ†ã‚¹ãƒˆ
        """
        print("\n" + "="*60)
        print("â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¸­æ–­ãƒ†ã‚¹ãƒˆ")
        print("="*60)

        prompt = "ã“ã‚Œã¯é•·ã„å›ç­”ãŒç”Ÿæˆã•ã‚Œã‚‹è³ªå•ã§ã™ã€‚ã§ãã‚‹ã ã‘è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"

        print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        print("â³ 3ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¦ç”Ÿæˆé–‹å§‹...\n")
        print("-" * 60)

        result = ""
        for token in self.generate_streaming(prompt, max_tokens=200, timeout_seconds=3.0):
            if token not in ["[ç”Ÿæˆå®Œäº†]", "[ç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]", "[APIã‚¨ãƒ©ãƒ¼]", "[ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ]"]:
                print(token, end="", flush=True)
                result += token

        print(f"\n-" * 60)
        print(f"ğŸ“ ä¸­æ–­ã¾ã§ã«ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {result.strip()}")
        print(f"âœ… ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¸­æ–­ãƒ†ã‚¹ãƒˆå®Œäº†\n")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    print("\n" + "="*60)
    print("ğŸš€ Gemma3:4b ç›´æ¥å®Ÿè¡Œãƒ†ã‚¹ãƒˆ (Ollama Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ)")
    print("="*60)

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        runner = Gemma3DirectRunner()

        # First stageãƒ†ã‚¹ãƒˆ
        first_stage_result = runner.test_first_stage()

        # Second stageãƒ†ã‚¹ãƒˆï¼ˆFirst stageã®çµæœã‚’ä½¿ç”¨ï¼‰
        second_stage_result = runner.test_second_stage(first_stage_result)

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»ä¸­æ–­ãƒ†ã‚¹ãƒˆ
        runner.test_timeout_interruption()

        print("\n" + "="*60)
        print("âœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("="*60)
        print("\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"  ãƒ»First Stage çµæœ: {first_stage_result}")
        print(f"  ãƒ»Second Stage çµæœ: {second_stage_result}")
        print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒOllama HTTP APIæ¯”ã§æ”¹å–„ã—ãŸã‹ç¢ºèª")
        print("  2. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¸­æ–­æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ãŸã‹ç¢ºèª")
        print("  3. æ”¹å–„ãŒã‚ã‚Œã°ã€NLGãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§å®Ÿè£…æ¤œè¨")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
